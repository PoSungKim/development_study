# SQL 옵티마이저
> 
* 

<hr>
<br>

## SQL 옵티마이징 원리

#### 

<br>

### 옵티마이저
* RBO (Rule-based Optimizer)
  * 대용량 데이터베이스 환경에 부적합하다
* CBO (Cost-based Optimizer)
  * 사용자 쿼리를 위해 후보군이 될만한 실행계획들을 도출하고, 데이터 딕셔너리 (Data Dictionary)에 미리 수집해 둔 통계정보를 이용해 각 실행계획의 예상비용을 산정하고, 그중 낮은 비용의 실행계획 하나를 선택
  * 통계정보
    * 데이터양, 칼럼 값의 수, 칼럼 값 분포, 인덱스 높이, 클러스터링 팩터
  * 최적화
    * Query Transformer
      * 사용자에게 전달받은 쿼리를 최적화에 유리한 형태로 변환
    * Estimator
      * 쿼리 오퍼레이션 각 단계의 선택도 (Selectivity), 카디널리티 (Cardinality), 비용 (Cost)을 계산하고, 궁극적으로는 실행계획 전체에 대한 비용을 계산
    * Plan Generator
      * 하나의 쿼리를 수행할 때, 실행계획 후보군들을 생성
  * 힌트
    * 명령어 (Directives)로 비용이 더 낮은 실행계획이 있더라도 힌트를 따라간다

<br>

### 실행계획 최적화
* Adaptive Direct Path Read
  * Direct Path Read를 사용할지 여부를 결정하는 기능
    * 버퍼캐시 크기 등
* Bind Variable Peeking (첫 실행계획을 수립할 때만이지, 런타임 때 다른 실행계획을 설립해서 선택하는, 즉 변화를 주는 기능은 아니기 때문에 Self-Learning Optimizer 기능은 아닌 것으로 보인다)
  * SQL이 첫 번째 수행될 때 함께 딸려 온 바인드 변수 값을 살짝 훔쳐보고 (Peek), 그 값에 대한 칼럼 분포를 이용해 실행계획을 결정하는 기능
  * 바인드 변수를 사용하면 히스토그램 정보를 활용하지 못하는 제약을 극복하기 위한 기능
* Self-Learning Optimizer O (기존에 선택했던 실행계획을 런타임 상황에 따라 다른 실행계획으로 변경하는 것이 주요 포인트인 것 같다)
  * Adaptive Cursor Sharing
    * 처음 실행 시 특정 실행계획으로 실행했다가 바인드 변수에 다른 값이 입력됐을 때 예상보다 많은 I/O가 발생하면 다른 실행계획을 추가로 생성하고, 이후로 바인드 변수 값 분포에 따라 다른 실행계획을 선택적으로 사용하는 기능
  * Statistics Feedback (Cardinality Feedback)
    * 최초 실행계획을 수립할 때 추정했던 카디널리티와 실제 실행 과정에 읽은 로우 수 간에 차이가 크다면, 조정된 카디널리티 값을 어딘가에 저장해 두었다가 다음번 실행 시에 그것을 사용함으로써 다른 실행계획이 수립되도록 하는 기능
  * Adaptive Plans
    * 런타임에 실행계획을 변경하는 기능
      * 통계정보 상 A 집합과 B 집합, 둘 다 작은 집합이라고 판단이 되어서 NL조인을 옵티마이저가 선택했지만, 실제 실행 과정에서는 먼저 읽은 A 집합에서 예상보다 많은 로우를 반환되면 Hash 조인으로 조인 메소드를 변경한다

<br>

### 옵티마이저가 사용하는 통계정보
* 오브젝트 통계
  * 테이블 통계
    * 레코드 수, 블록 수, 평균 행 길이 등
  * 인덱스 통계
    * 인덱스 높이, 리프 블록 개수, 클러스터링 팩터 등
  * 칼럼 통계
    * 중복을 제거한 칼럼 값의 수, 최소값, 최대값, Null 값 개수, 히스토그램 등
* 시스템 통계
  * CPU 속도, Single Block I/O 속도, Multiblock I/O 속도, 평균적인 Multiblock I/O 개수 등

<br>

### 최적화 목표 (optmizer_mode)
* 옵션
  * ALL_ROWS
    * 전체 처리속도 최적화 : 쿼리 결과집합 전체를 읽는 것을 전제로 시스템 리소스 (I/O, CPU, 메모리 등)를 가장 적게 사용하는 실행계획을 선택한다
  * FIRST_ROWS, FIRST_ROWS_N
    * 최초 응답속도 최적화 : 전체 결과집합 중 앞쪽 일부만 읽다가 멈추는 것을 전제로 응답 속도가 가장 빠른 실행계획을 선택한다
    * Table Full Scan 보다 인덱스를 더 많이 선택하고, 해시 조인보다 NL 조인을 더 많이 선택하는 경향을 보인다
* 환경
  * OLTP
    * 요즘은 보통 3-Tier (Client-Server-DB) 아키텍처에서 클라이언트와 서버 간 연결을 지속하지 않는 환경이므로 오픈 커서를 계속 유지할 수 없어서 일반적으로 페이징 처리 기법을 사용한다
    * 따라서, 대량 데이터 중 일부만 Fetch 하다가 끝나는 것이 아니라, rownum으로 결과집합 자체를 10~20건으로 제한하는 페이징 기법을 통해 집합 자체를 소량으로 정의해서 모두 Fetch 하는 방식을 택한다면, (FIRST_ROWS, FIRST_ROWS_N)가 아니라, (ALL_ROWS) 즉 전체 처리속도 최적화가 더 적절한 설정이다

<br>

### 옵티마이저 행동에 영향을 미치는 요소
* 옵티마이징 팩터
  * 인덱스, IOT, 클러스터링, 파티셔닝 등 오브젝트 구성
* DBMS 제약 설정
  * PK, FK, Check, Not Null 등
* 통계정보
* 옵티마이저 힌트
* 옵티마이저 관련 파라미터

<br>

### 온라인 옵티마이저의 한계
* 한계 발생 이유
  * 온라인 옵티마이저는 정해진 시간 내에 빠르게 최적화를 수행해야 하기 때문에 정보를 충분히 활용하지 못한다
  * 오라클의 경우, 튜닝 모드에서 오프라인 옵티마이저(=자동 튜닝 옵티마이저)를 구동하면, 시간 제약 없이 다이나믹 샘플링을 포함한 다양한 정보와 기업을 활용하므로 훨씬 더 완벽한 실행계획을 생성해 낸다
* 한계 요소
  * 부족한 옵티마이징 팩터
    * 인덱스, IOT, 클러스터링, 파티셔닝 등 오브젝트 구성
  * 부정확한 통계
    * 정보 수집 및 보관 비용 측면의 한계 (샘플링 비율, 수집 주기 등)
  * 결합 선택도 산정의 어려움
  * 바인드 변수 사용 시, 히스토그램 사용에 제약
  * 비현실적인 가정과 규칙에 의존
  * 최적화 시간에 허용된 시간 제약

<br>

### 선택도 (Selectivity) vs 카디널리티 (Cardinality)
* 선택도 (Selectivity)
  * 전체 레코드 중에서 조건절에 의해 선택되는 레코드 비율
  * (= 조건) 선택도 = 1 / NDV (Number of Distinct Values)
* 카디널리티 (Cardinality)
  * 전체 레코드 중에서 조건절에 의해 선택되는 레코드 개수
  * 카디널리티 = 총 로우 수 * 선택도 = 총 로우 수 / NDV

<br>

### 선택도 (Selectivity) vs 카디널리티 (Cardinality)
* 데이터
  * 상품 테이블 총 건수 = 100,000
  * 상품분류 = { 가전, 의류, 식음료, 생활용품 }
* SQL
  ```sql
  SELECT *
  FROM   상품
  WHERE  상품분류 = :prd_cls;
  ```
* NDV (Number of Distinct Values)
  * 4 = size of { 가전, 의류, 식음료, 생활용품 }
* 선택도 (Selectivity)
  * 25%
* 카디널리티 (Cardinality)
  * 25,000

<br>
<hr>
<br>
