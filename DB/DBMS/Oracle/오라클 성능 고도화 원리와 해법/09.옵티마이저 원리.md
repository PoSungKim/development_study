# 옵티마이저 원리
> 
* 

<hr>
<br>

## 옵티마이저
#### 

<br>

### 옵티마이저란?
* 옵티마이저
  * 사용자가 요청한 SQL을 가장 효율적이고 빠르게 수행할 수 있는 최적(최저비용)의 처리경로를 선택해 주는 DBMS의 핵심엔진
  * 구조화된 질의언어(SQL)로 사용자가 원하는 결과집합을 정의하면 이를 얻는 데 필요한 처리절차 (프로시저)는 DBMS에 내장된 옵티마이저가 자동으로 생성
* 유형
  * 규칙기반 옵티마이저 (Rule-Based Optimizer, RBO)
  * 비용기반 옵티마지어 (Cost-Based Optimizer, CBO)

<br>

### 규칙기반 옵티마이저
* 규칙기반 혹은 휴리스틱 (Heuristic) 옵티마이저
  * 미리 정해 놓은 우선순위에 따라 액세스 경로 (Access Path)를 평가하고 실행계획을 선택한다
  * 데이터 특성 (데이터량, 값의 수, 칼럼 값 분포, 인덱스 높이, 클러스터링 팩터...)을 고려하지 않기 때문에 RBO는 대용량 데이터를 처리하는 데 있어 합리지 못할 경우가 많다
    * 예) 조건절 칼럼에 인덱스가 있으면 무조건 인덱스 사용; 항상 인덱스를 신뢰하며, Full Table Scan과의 손익을 따지지 않는다
  * 즉, RBO는 어떻게 동작할지 예상이 가는 옵티마이저

<br>

### 비용기반 옵티마이저
* 비용기반 옵티마이저
  * 비용을 기반으로 최적화를 수행한다
* 실행계획을 수립할 때 판단 기준이 되는 비용은 어디까지나 예상치
  * 데이터 딕셔너리 (Data Dictionary)에 미리 구해놓은 테이블과 인덱스에 대한 여러 통계정보를 기초로 각 오퍼레이션 단계별 예상 비용을 산정하고, 이를 합산한 총비용이 가장 낮은 실행계획 하나를 선택
* 동적 샘플링 (Dynamic Sampling)
  * 쿼리를 최적화할 때 미리 구해놓은 통계정보를 이용한다
  * 다만, 만약 테이블과 인덱스에 대한 통계정보가 없거나 너무 오래돼 신뢰할 수 없을 때 옵티마이저가 동적으로 샘플링 수행

<div align="center">
  <img width="80%" src="https://github.com/PoSungKim/development_study/assets/37537227/b0eb6d84-1e03-4879-9e8b-870dd920412a">
</div>

* Optimizer
  * Query Transformer
    * 사용자가 던진 SQL을 우선 최적화하기 쉬운 형태로 변환을 시도한다
  * Estimator
    * 쿼리 오퍼레이션 각 단계의 선택도(Selectity), 카디널리티 (Cardinality), 비용 (Cost)을 계산하고, 궁극적으로는 실행계획 전체에 대한 총 비용을 계산
  * Plan Generator
    * 하나의 쿼리를 수행하는 데 있어, 후보군이 될만한 실행계획들을 생성해내는 역할
* 스스로 학습하는 옵티마이저(Self-Learning Optimizer)
  * v$sql, v$sql_plan_statistics, v$sql_plan_statistics_all, v$sql_workarea 등에 SQL 별로 저장된 수많은 런타임 수행 통계를 보면 앞으로 옵티마이저의 발전 방향을 예상 가능
  * 옵티마이저는 지금까지 오브젝트 통계와 시스템 통계로부터 산정한 '예상' 비용만으로 실행계획을 수립했지만 앞으로는 예상치가 빗나갔을 때 이들 런타임 수행 통계를 보고 실행계획을 조정할 수도 있음

<br>

### 옵티마이저 모드 
* 모드 변경 가능 레벨
  * 시스템, 세션, 쿼리
  ```sql
  alter system set optimizer_mode = all_rows; -- 시스템 레벨 변경
  alter session set optmizer_mode = all_rows; -- 세션 레벨 변경
  select /*+ all_rows */ * from t where ...;  -- 쿼리 레벨 변경
  ```
* 모드
  * rule --> RBO
    * RBO 모드
  * all_rows --> CBO
    * 쿼리 최종 결과집합을 끝까지 Fetch하는 것을 전제로, 시스템 리소스 (I/O, CPU, 메모리 등)를 가장 적게 사용하는 실행계획 선택
    * DML 문장은 일부 데이터만 가공하고 멈출 수 없으므로 옵티마이저 모드에 상관없이 항상 all_rows 모드로 작동
      * select 문장도 union, minus 같은 집합(set) 연산자나 for update절을 사용하면 all_rows 모드로 작동
  * first_rows --> RBO + CBO
    * 전체 결과집합 중 일부 로우만 Fetch하다가 멈추는 것을 전제로, 가장 빠른 응답 속도를 낼 수 있는 실행계획을 선택
    * 사용자가 만약 끝까지 Fetch한다면, 오히려 더 많은 리소스를 사용하고 전체 수행 속도도 느려질 수 있다
    * 비용과 규칙을 혼합한 옵티마이저이기 때문에, 규칙에 따르다보면, 손익분기점 (Table Full Scan vs Index Full Scan)을 고려하지 못하고, 무조건 Index Full Scan을 탈 수가 있다
    ```sql
    -- TABLE ACCESS FULL
    select /*+ all_rows */ * from t_emp
    where  sal >= 5000
    order by empno, no;
    ```
    ```sql
    -- INDEX FULL SCAN > TABLE ACCESS BY INDEX ROWID
    select /*+ first_rows */ * from t_emp
    where  sal >= 5000
    order by empno, no;
    ```
  * first_rows_n --> CBO
    * 사용자가 처음 n개 로우만 Fetch하는 것을 전제로, 가장 빠른 응답 속도를 낼 수 있는 실행계획을 선택
    * 세팅 방법
      ```sql
      alter session set optimizer_mode = first_rows_100 -- first_rows_1, first_rows_10, first_rows_100, first_rows_1000
      ``` 
      ```sql
      select /*+ first_rows(100) */ * from t where ...;
      ```
    * CBO이기 때문에, 읽을 데이터가 적을 때는 인덱스, 읽을 데이터가 많을 때는 테이블
      ```sql
      -- Index Full Scan > Table Access By Index Rowid
      select /*+ first_rows(10) */ * from t_emp
      where  sal >= 2000
      order by empno, no;
      ```
      ```sql
      -- Table Access Full > Sort Order By
      select /*+ first_rows(100) */ * from t_emp
      where  sal >= 2000
      order by empno, no;
      ```  
  * CHOOSE
    * 액세스되는 테이블 중 적어도 하나에 통계정보가 있다면 CBO, 그중에서도 all_rows 모드를 선택; 어느 테이블에도 통계정보가 없으면 RBO 선택
* 옵티마이저 모드 선택
  * 과거의 컨벤션 
    * OLTP : first_rows
    * OLAP : all_rows
  * 요즘의 컨벤션
    * OLTP : all_rows
    * OLAP : all_rows
  * OLTP가 all_rows로 바뀐 이유
    * 요즘은 오픈 커서를 사용하지 않고, rownum 등을 활용하여 페이징처리 한다
    * 페이징처리는 전체 결과집합에서 특정 건수만 fetch하는게 아니라, 전체결과집합 자체를 작게 만들어서 모두 fetch하는 형태이기 때문에 all_rows가 적합하다

<br>
<hr>
<br>

## 옵티마이저 행동에 영향을 미치는 요소
#### 

<br>

### SQL과 연산자 형태
* 동일한 결과집합을 갖는 SQL이더라도, 작성된 형태 또는 사용한 연산자 (=, in, like, between, 부등호 등)를 사용했는지에 따라 영향도가 있을 수 있다

<br>

### 인덱스, IOT, 클러스터링, 파티셔닝, MV 등 옵티마이징 팩터
* 동일한 쿼리더라도, 구성도에 따라 실행계획과 성능이 크게 달라진다

<br>

### 제약 설정 : PK, FK, Not Null, Check
* 데이터베이스가 논리적으로 의미 있는 자료만을 포함하도록 하는 데이터 무결성 규칙
  * 개체 무결성 (Entity Integrity)
  * 참조 무결성 (Referential Integrity)
  * 도메인 무결성 (Domain Integrity)
  * 사용자 정의 무결성 (또는 업무 제약 조건) 
* PK 제약과 옵티마이저

  ```sql
  select sum(주문수량), sum(주문금액), count(*), count(distinct 고객번호)
  from   주문
  where  고객번호 in (select 고객번호 from 고객
                    where  가입일자 >= trunc(add_months(sysdate, -12))
  and    주문일자 <= trunc(add_months(sysdate, -1));  
  ```
  
  * 서브쿼리 Unnesting, 수정 가능 조인 뷰 (Updatable Join View)
* FK 제약과 옵티마이저
  * 조인 제거 (Join Elimination), Reference 파티셔닝
* Not Null 제약과 옵티마이저

  ```sql
  select deptno, count(*) from emp group by deptno;
  ```
  
  * deptno 칼럼이 Not Null이고 Index가 있다면, Index Full Scan 혹은 Index Fast Full Scan
  * deptno 칼럼이 Not Null이 아니면, Table Full Scan
* Check 제약과 옵티마이저

  ```sql
  alter table emp modify sal check (sal <= 5000);
  ```
  ```sql
  select * from emp where sal > 5000;
  ```
  ```
  Rows   Row Source Operation
  ----   -------------------------------------------
  0      FILTER
  1        TABLE ACCESS FULL EMP
  ```

<br>

### 옵티마이저 힌트
* 옵티마이저는 아래와 같은 경우가 아니면 힌트를 가장 우선적으로 따른다
  * 문법적으로 맞지 않게 힌트를 기술
  * 잘못된 참조 사용 (없는 테이블이나 별칭)
  * 의미적으로 맞지 않게 힌트를 기술 (unnest와 push_subq 함께 사용)
  * 논리적으로 불가능한 액세스 경로 (등치조건인데 Hash Join 유도, Nullable 칼럼에 인덱스를 통한 전체 건수 count 유도)
  * 버그
* 옵티마지어는 기본적으로 힌트의 내용을 먼저 따르고 남은 부분만을 자신의 판단에 따라 최적화한다

  ```sql
  select /*+ ordered */ count(*)
  from   t1, t2, t3, t4, t5
  where  t1.a = ...;
  ```

<br>

### 통계정보 : 오브젝트 통계, 시스템 통계
* CBO의 모든 판단 기준은 통계정보

<br>

### 옵티마이저 관련 파라미터
* 모든 조건이 동일하나, 오라클 버전을 업그레이드하면 옵티마이저가 다르게 작동할 수 있다
* 옵티마지어 관련 파라미터 

  ```sql
  select name, value, isdefault, default_value
  from   v$sys_optimizer_env;
  ```
  
  ```sql
  alter system set optimizer_features_enable = "9.2.0.4";
  ```

<br>

### DBMS 버전과 종류
* 같은 SQL도 DBMS 종류 (Oracle, SQL Server, Sybase, DB2)에 따라 내부적으로 처리하는 방식이 다르다

  ```sql
  select max(empno) from emp;
  ```
  
  ```sql
  select min(empno) mn, max(empno) mx from emp;
  ```

* M쪽 집합을 기준으로 1쪽 집합과 Outer조인하면 결과 건수는 M쪽 힙합으로 고정된다
  * 조인 조인 외에 어디에도 1쪽 집합을 참조하지 않는다면 1쪽 집합과는 조인 액세스를 하지 않아도 된다
    * 1쪽 테이블 조인 칼럼에 PK가 설정돼 있어야 하는 조건이 붙는다
  * 이런 기능이 Join Elimination, Table Elimination

  ```sql
  select e.empno, e.ename, e.sal, e.hiredate
  from   emp e, dept d
  where  d.deptno(+) = e.deptno;
  ```

  ```
  Rows   Row Source Operation
  ----   -------------------------------------------
  14     TABLE ACCESS FULL EMP
  ```
  
<br>
<hr>
<br>

## 옵티마이저의 한계
#### 옵티마이저가 절대 완벽할 수 없으며, 여러 가지 제약과 한계점들을 극복하며 발전해 나가는 과정 속에 있다

<br>

### 자동 튜닝 옵티마이저
* 온라인 (런타임) 옵티마이저 vs 오프라인 (자동 튜닝) 옵티마이저
  * 온라인 : 보통 아는 옵티마이저
  * 오프라인 : 통계를 분석하고, SQL 프로파일링 (Profiling)을 실시하며, 액세스 경로 및 SQL 구조 분석을 통해 SQL 튜닝 실시
* 자동 튜닝 옵티마이저는 동적 샘플링을 통해 부가적인 정보를 수집하고,부분적인 실행을 통해 에측치를 검증함으로써 잘못된 정보를 조정한다
  * 다만, 런타임 오티마이저보다 보다 긴 시간 (10분 정도)가 소요되기 때문에, OLTP 환경에서는 도입되기 어렵다

<br>

### 부족한 옵티마이징 팩터
* 옵티마이저는 주어진 환경에서 최선을 다할 뿐 적절한 옵티마이징 팩터를 제공하는 것은 개발자의 몫

<br>

### 부정확한 통계
* 현실적으로 100% 정확한 통계를 유지하기는 어렵다
  * 샘플링 방식, 칼럼 분포도, 통계 수집 주기 등 고려 필요
  
<br>

### 히스토그램의 한계
* 히스토그램 버킷 개수가 254개까지만 허용된다는 점도 옵티마이저에겐 중요한 제약사항
  * 높이균형 (height-balanced) 히스토그램을 사용하게 되므로 발생 빈도가 낮은 값들 (non-popular value)에 대한 정확한 분포를 반영할 수 없다

<br>

### 바인드 변수 사용 시 균등분포 가정
* 칼럼 히스토그램이 잇으면 옵티마이저가 그것을 가지고 조건절에 대한 선택도를 구한다
* 다만, 바인드 변수를 사용한 SQL에서는 옵티미이저가 균등분포를 가정하고 계산하기 때문에 무용지물이 된다
* 특히, OLTP 환경에서는 라이브러리 캐시를 피하기 위해 바인드 벼수를 적극 사용하는 것이 필수 권고사항이기 때문에, 바인드 변수를 사용해야 한다 

<br>

### 결합 선택도 산정의 어려움
* 조건절 칼럼이 서로 상관관계에 있으면 정확한 데이터 분포와 카디널리티를 산정하기 어렵다
  ```sql
  select * from 사원 where 직급 = '부장' and 연봉 >= 5000;
  ```
* 통계
  * 직급
    * 부장, 과장, 대리, 사원 (25%)
  * 연봉
    * >= 5000 (10%)
  * 추정치
    * 상단 쿼리의 조건에 부합하는 사원 수를 25(1000 * 0.25 * 0.1)명으로 추정한다
  * 실제값
    * 연봉 5000만원 이상의 사원들은 모두 부장으로 실제로는 10(1000 * 0.1)명이었다
* 고민 포인트
  * 조합이 기하급수적으로 증가하기 때문에 모든 칼럼 간 상관관계와 결합 선택도를 미리 저장하는 것은 불가능하다
  * 다만, 11g부터는 사용자가 지정한 칼럼들에 대해 결합 선택도를 미리 수집해 두는 기능을 제공하기 시작했다

<br>

### 비현실적인 가정
* 비현실적 가정 예시
  * Single Block I/O와 Multiblock I/O 비용을 같게 평가
  * 다른 세션이나 다른 쿼리문에 의해 데이터 블록들이 이미 버퍼 캐시에 캐싱돼 있을 가능성을 배제
* 보정 파라미터
  * optimizer_index_caching
  * optimizer_index_cost_adj

<br>

### 규칙에 의존하는 CBO
* 비용기반 옵티마이저라 하더라도 부분적으로 규칙에 의존한다
  * 원격 (remote) 테이블이나 External 테이블에 대해서는 카디널리티, 평균 행 길이, 블록 수, 그리고 각종 인덱스 관련 통계항목들에 대해 고정된 상수 값을 사용한다
  * 옵티마이저 모드를 first_rows로 설정했을 때, order by 소트를 ㅐ체할 인덱스가 있으면 무조건 인덱스를 사용하는 것도 좋은 예시
* 알파벳순 인덱스 선택 규칙
  * t_x01, t_x02의 예상 비용이 동일하다면, 옵티마이저는 이름순으로 t_x01을 택한다
  ```sql
  create table t
  as
  select rownum a, rownum b from dual
  connect by level <= 10000;

  create index t_x01 on t(a);

  create index t_x02 on t(b);

  exec dbms_stats.gather_table_stats(user, 't');
  ```
  ```sql
  set autotrace traceonly exp
  select * from t where a = 1 and b = 1;
  ```
  ```
  Id     Operation
  ----   -------------------------------------------
  0      SELECT STATEMENT
  1        TABLE ACCESS BY INDEX ROWID (T)
  2          INDEX RANGE SCAN (T_X01)
  ```
  ```sql
  alter index t_x01 rename to t_x03;
  select * from t where a = 1 and b = 1;
  ```
  ```
  Id     Operation
  ----   -------------------------------------------
  0      SELECT STATEMENT
  1        TABLE ACCESS BY INDEX ROWID (T)
  2          INDEX RANGE SCAN (T_X02)
  ```
  * ORDER_PK, ORDER_N01의 예상 비용이 동일하다면, 옵티마이저는 이름순으로 ORDER_N01을 택한다
  ```
  ORDER_PK : 고객번호 + 주문일자
  ORDER_N01 : 고객번호 + 배송일자
  ```
  ```sql
  where 고객번호 = :cust_no
  and   주문일자 = :ord_dt
  ```

<br>

### 하드웨어 성능 특성 
* 옵티마이저는 기본적으로 옵티마이저 개발팀이 사용한 하드웨어 사양에 맞추져 있다
  * 따라서, 실제 운영 시스템의 하드웨어 사양이 그것과 다를 때 옵티마이저가 잘못된 실행계획을 수립할 가능성이 높아진다
* 이를 해결하고자, 오라클 i9부터 시스템 통계를 수집하는 기능이 도입되었다
* 동적 실시간 최적화 (Dynamic Runtime Optimizations)
  * 하드웨어 성능 특성을 반영한 실행계획을 수립하더라도, 쿼리가 수행되는 당시의 시스템 부하 정도에 따라서 최적이 아닐 수 있다
  * 따라서, 시스템 부하에 따라 실행전략을 동적으로 조정하는 최적화 기법이 도입되고 있다
    * 쿼리가 수행되는 시점의 시스템 상태에 따라 하드웨어 리소스(CPU와 메모리)를 적절히 배분해 주는 것에 있다
    * 예시)
      * 시스템 부하 정도에 따라 병렬 쿼리의 프로세스 개수를 오라클이 동적으로 조절해 주는 기능
      * 9i부터 PGA 메모리 크기를 자동으로 조절해 주는 기능
      * 10g부터 SGA를 구성하는 서브 메모리 영역을 자동으로 조절해 주는 기능
  * 쿼리 최적화 : 단일 SQL문 성능 최적화
  * 동적 실시간 최적화 : 수많은 SQL이 동시에 수행되는 환경에서 시스템 전체 최적화

<br>
<hr>
<br>

## 통계정보 I
#### 실행계획을 수립할 때 CBO는 SQL 문장에서 액세스할 데이터 특성을 고려하기 위해 통계를 이용한다

<br>

### 테이블 통계
```sql
analyze table emp compute statistics for TABLE;
analyze table emp estimate statistics sample 5000 rows for TABLE;
analyze table emp estimate statistics sample 50 precent for TABLE;
```
* compute : 전수조사
* estimate : 표본조사

<br>

### 인덱스 통계 
* 기존 인덱스 및 테이블 케이스)
```sql
analyze INDEX emp_pk compute statistics;
analyze table emp compute statistics for ALL INDEXES;
analyze table emp compute statistics for TABLE for ALL INDEXES;

select *
from   dba_tables
where  owner = 'SCOTT'
and    table_name = 'EMP;
```
* 최초 생성 및 재성생 케이스)
```sql
create index emp_ename_idx on emp(ename) COMPUTE STATISTICS;
alter  index emp_ename_idx rebuild COMPUTE STATISTICS;

select *
from   dba_tables
where  owner = 'SCOTT'
and    table_name = 'EMP
and    index_name = 'EMP_PK';
```

<br>

### 칼럼 통계 
```sql
analyze table emp compute statistics for ALL COLUMNS SIZE 254;
analyze table emp compute statistics for COLUMNS ENAME SIZE 10, SAL SIZE 20;
analyze table emp compute statistics for COLUMNS SIZE 20 ENAME, SAL, HIREDATE;
```
```sql
analyze table emp compute statistics
for table
for all indexes
for all indexed columns size 254;
```
```sql
select *
from   dba_tables
where  owner = 'SCOTT'
and    table_name = 'EMP
and    index_name = 'EMP_PK';
```
 
<br>

### 시스템 통계
* 시스템 통계를 제대로 활용하려면 Workload 시스템 통계가 바람직하지만, 이를 수집하기 어려운 환경에서는 NoWorkLoad 시스템 통계를 사용한다
  * Workload 시스템 통계 : 실제 애플리케이션에서 발생하는 부하를 기준으로 각 항목의 통계치 측정
  * NoWorkLoad 시스템 통계 : 모든 데이터파일 중에서 오라클이 무작위로 I/O를 발생시켜 통계 수집
  * 즉, Workload/NoWorkLoad 시스템 통계 : 모두 시스템 부하가 있는 상태에서 수집되는 것이 바람직
* 항목
  * CPU 속도
  * 평균적인 Single Block I/O 속도
  * 평균적인 Multiblock I/O 속도
  * 평균적인 Multiblock I/O 속도
  * I/O 서브시스템의 최대 처리량 (Throughput)
  * 병렬 Slave의 평균적인 처리량 (Throughput)
  ```sql
  select sname, pname, pval1, pval2 from sys.aux_stats$;
  ```
* Workload 시스템 통계
  * 9i에서 도입된 Workload 시스템 통계 : 애플리케이션으로부터 일정 시간 동안 발생한 시스템 부하를 측정/보관함으로써 그 특성을 최적화 과정에 반영할 수 있게 한 기능
  * Workload 시스템 통계 수집 전략이 중요
    * 대표성 있는 시간대를 선택해 현 운영 서버에서 실제로 수집한 시스템 통계를 테스트 서버로 Export/Import 하고서 개발을 진행하면 된다

| 통계항목 | 설명                                                                                |
|----------|-------------------------------------------------------------------------------------|
| cpuspeed | 현재 시스템에서 단일 CPU가 초당 수행할 수 있는 표준 오퍼레이션 개수 (단위: 백만/초) |
| sreadtim | 평균적인 Single Block I/O 속도 (단위: ms = 1/1000초)                                |
| mreadtim | 평균적인 Multiblock I/O 속도 (단위: ms = 1/1000초)                                  |
| mbrc     | Multiblock I/O 방식을 사용할 때 평균적으로 읽은 블록 수                             |
| maxthr   | I/O 서브시스템의 최대 처리량 (단위: 바이트/초)                                      |
| slavethr | 병렬 Slave의 평균적인 처리량(단위: 바이트/초)                                       |

* NoWorkload 시스템 통계
  * Workload 시스템 통계가 수집되기 전까지 반영되는 NoWorkload 시스템 통계의 추정값
    * cpuspeed = cpuspeednw
    * mbrc = db_file_multiblock_read_count
    * sreadtim = ioseektim + db_block_size / iotfrspeed
    * mreadtim = ioseektim + mbrc * db_block_size / iotfrspeed
   
| 통계항목   | 기본 값                             | 설명                                                                                                                                                                                                                                                                    |
|------------|-------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| cpuspeednw | 데이터베이스 최초 기동 시 측정된 값 | NoWorkload 상태에서 측정된 CPU 속도 (단위: Millions/sec)                                                                                                                                                                                                                |
| ioseektim  | 10ms                                | I/O Seek Time을 뜻하며 데이터를 읽으려고 디스크 헤드(head)를 옮기는 데 걸리는 시간을 나타낸다. 대개 5~15 ms의 수치를 보이며, 디스크 회전 속도와 디스크 또는 RAID 스팩에 따라 달라진다. <br><br>io seek time = seek time + latency time + operating system overhead time |
| iotfrspeed | 4096 bytes/ms                       | I/O Transfer 속도를 뜻하며, 하나의 OS 프로세스가 I/O 서브시스템으로부터 데이터를 읽는 속도를 나타낸다. 이 값은 초당 몇 MB에서 수 백 MB까지 아주 다양하다.                                                                                                               |


<br>
<hr>
<br>

## 카디널리티
#### 데이터 딕셔너리에 저장된 통계정보를 사용하는 옵티마이저
#### 인덱스, 클러스터 등 옵티마이징 팩터가 동일한 상황에서 CBO 행동에 결정적 영향을 주는 요소는 무엇보다 통계정보

<br>

### 선택도
* 선택도 
  * 전체 대상 레코드 중에서 특정 조건에 의해 선택될 것으로 예상되는 레코드
  ```
  선택도 > 카디널리티 > 비용 > 액세스 방식, 조인 순서, 조인 방법 등 결정
  ```
* 히스토그램 없이 등치 (=) 조건에 대한 선택도 구하는 공식
  ```
  선택도 = 1 / Distinct Value 개수 = 1 / num_distinct
  ```
* 히스토그램 없이 부등호, between 같은 범위검색 조건에 대한 선택도를 구하는 공식 (상수 조건)
  ```
  선택도 = 조건절에서 요청한 값 범위 / 전체 값 범위
  ```
* 값 범위는 칼럼 통계에서 수집된 high_value, low_value, num_distinct 등을 이용해 구한다 (dba_tab_col_statistics)

  | num_rows | num_distict | low_value | high_value |
  |----------|-------------|-----------|------------|
  | 1000000  | 100         | 1         | 1000       |

<br>

### 카디널리티
* 카디널리티
  * 특정 액세스 단계를 거치고 나서 출력될 것으로 예상되는 결과 건수
  ```
  카디널리티 = 총 로우 수 * 선택도
  ```
  * 칼럼 히스토그램 없을 때
  ```
  카디널리티 = 총 로우 수 * 선택도 = num_rows / num_distinct
  ```
* 통계
  * 테이블 통계 (num_rows) : dba_tables, dba_tab_statistics
  * 칼럼 통계 (num_distinct) : dba_tab_columns, dba_tab_col_statistics
* 선택도 및 카디널리티 계산식 테스트
  * 칼럼 히스토그램을 생성하지 않은 상태
    * 히스토그램이 없으므로 평균적인 칼럼 분포를 가정해 정해진 계산식에 따라 선택도와 카디널리티 계산
  * 칼럼 히스토그램이 생성되어 있는 상태
    * 바인드 변수를 사용하지 않은 경우
      * 히스토그램이 있으므로 공식에 의존하지 않고 미리 구해놓은 히스토그램을 이용하여 선택도와 카디널리티 계산
    * 바인드 변수를 사용한 경우
      * 히스토그램이 있더라도바인드 변수를 사용하면 평균적인 분포를 가정해 카디널리티 계산

<br>

### NULL 값을 포함할 때

<br>
<hr>
<br>

## 
#### 

<br>

### 

<br>
<hr>
<br>

