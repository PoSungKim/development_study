# IO 효율화 원리
> 데이터베이스 성능 튜닝의 3대 핵심 요소 (라이브러리 캐시 최적화, 데이터베이스 Call 최소화, I/O 효율화 및 버퍼캐시 최적화)
* I/O 효율화 및 버퍼캐시 최적화 : 인덱스 원리, 조인 원리, 옵티마이저 원리에 대한 이해가 필수

<hr>
<br>

## 블록 단위 IO
#### 오라클을 포함한 모든 DBMS는 블록 (Block) 단위로 버퍼 캐시 IO 및 데이터 파일 IO 발생 (** 타 DBMS에서는 페이지 (Page)라는 용어로 표현)
#### SQL 성능을 좌우하는 가장 중요한 성능지표는 액세스하는 블록 개수이며, 옵티마이저의 판단에 가장 큰 영향을 미치는 것도 액세스해야 하는 블록 개수 (Full Table Scan vs Index Scan)

<br>

### 블록 단위 IO
* 액세스
  * Sequential Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 모든 레코드를 순차적으로 읽는 패턴
  * Random Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 한 건의 레코드만 읽을 수도 있는 패턴
* 블록 단위 IO
  * 메모리 버퍼 캐시에서 블록을 읽고 쓸 때
  * 데이터파일에 저장된 데이터 블록을 직접 읽거나 쓸 때 (Direct Path I/O)
  * 데이터파일에서 DB 버퍼 캐시로 블록을 적재할 때 : Single Block Read 또는 Multiblock Read 방식을 사용
  * 버퍼 캐시에서 변경된 블록을 다시 데이터파일에 저장할 때 : Dirty 버퍼를 주기적으로 데이터파일에 기록하는 것을 말하며, DBWR 프로세스에 의해 수행된다. 성능 향상을 위해 한 번에 여러 블록씩 처리한다
* 딕셔너리 캐시는 Row 단위 IO
* 오라클에서 허용하는 블록 크기 (db_block_size) : 2,4,8,16,32,64K
  * 다른 크기의 블록을 사용하기 위해서는 별도의 테이블스페이스 및 버퍼 Pool 구성 필요

<br>

### Sequential vs. Random 액세스

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/039ddd54-85b6-45a6-8f7c-b92946318a75">
</div>

* Sequential Access
  * 의미 : 레코드간 논리적 도는 물리적인 순서를 따라 차례대로 읽어 나가는 방식
    * 인덱스 리프 블록에 위치한 모든 레코드는 포인터를 따라 논리적으로 연결되어 있어서, 이 포인터를 따라 스캔하는 방식도 Sequential Access
    * 테이블 레코드 간에는 포인터로 연결되어 있지는 않지만 테이블 스캔할 때는 물리적으로 저장된 순서대로 읽어 나가므로 해달 방식도 Sequential Access
  * 성능 향상 방법
    * Multiblock I/O, 인덱스 Prefetch
* Random Access
  * 의미 : 레코드간 논리적, 물리적 순서를 따르지 않고, 한 건을 읽기 위해 한 블록씩 접근하는 방식
    * 주로 (4), (6)에서 성능 저하 발생
    * 하지만, NL조인의 Inner Table 액세스를 위한 (1), (2), (3)에서도 성능 저하 영향 발생 가능
  * 성능 향상 방법
    * 버퍼 Pinning, 테이블 Prefetch
* Sequential 액세스가 항상 Random Access보다 효율적인 것은 아니다
  * Seuqential 액세스의 경우, 선택도가 중요
    * 선택도 : 총 읽은 레코드에서 결과 집합으로 선택되는 비중
    * ex) Sequential Access로 100개를 읽었어도 그 중 99개를 버리고 1개의 결과 집합만 취한다면 Random Access보다 나을 것이 없다
* I/O 튜닝의 핵심 원리
  * Sequential 액세스의 선택도 (Selectivity)를 높인다
  * Random 액세스 발생량을 줄인다
 
<br>

### Sequential 액세스 선택도 높이기
* 49,906건이 담긴 테이블 (t))
```sql
CREATE TABLE t 
AS
SELECT * FROM all_objects
ORDER BY dbms_random.value;
```
* 24,613건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (49%) => 나쁘지 않은 Table Full Scan 효율성)
  * 읽은 블록 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'; 
```
* 1건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (0.002%) => 매우 낮은 Table Full Scan 효율성)
  * 읽은 블록 (CR) 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```
* 테이블 스캔 후 읽은 레코드들이 대부분 필터링되어 일부만 선택된다면 인덱스 사용이 더 효율적)
  * 1건의 결과집합 (INDEX RANGE SCAN T_IDX)
  * 읽은 블록 (CR) 76개
```sql
CREATE INDEX t_index ON t(owner, object_name);

SELECT  /*+ index(t t_idx) */ count(*) FROM t
WHERE   owner LIKE 'SYS%'
AND     object_name = 'ALL_OBJECTS';
```
* 인덱스로 읽은 레코드 개수 계산 예시)
  * 14,587건 Index Scan => 선택도 (0.007%) => Index Scan (Sequential Access)에서 비효율성 발생 가능
  * 인덱스 스캔도 충분히 비효율성이 발생 가능하다는 점을 인지해야함
    * 인덱스는 테이블과 달리 정렬된 순서를 유지하므로 일정 범위를 읽다가 멈출 수 있다는 점만 다르다
    * 다만, 인덱스 스캔의 효율은 조건절에 사용된 컬럼과 연산자 형태, 인덱스 구성에 의해 영향을 받는다
```sql
SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    ((owner = 'SYS' AND object_name >= 'ALL_OBJECTS') or (owner > 'SYS'));
```
* 인덱스 칼럼 순서를 변경한 예시)
  * from (owner, object_name) => to (object_name, owner)
  * 읽은 블록 (CR) 2개 
    * 인덱스 루트 블록 1개 + 리프 블록 1개
  * 1건의 결과집합 + 1건 INDEX RANGE SCAN T_IDX (정확히는 One-plus 스캔까지 2건) => 선택도 (100%) => 효율적인 Index Scan (Sequential Access) 발생
```sql
DROP INDEX t_idx;
CREATE INDEX t_index ON t(object_name, owner);

SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```

<br>

### Random 액세스 발생량 줄이기
* 인덱스에 속하지 않는 칼럼 (object_id)을 참조하도록 쿼리를 변경함으로써 테이블 액세스 발생하는 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=739 ...)
    * 22934 | INDEX RANGE SCAN T_IDX (cr=51)
* 분석
  * 22,934 번만큼 테이블 방문 + 688 (739 - 51) 블록을 Random 액세스
  * 테이블을 22,934번만큼 방문하면서 내부적으로 22,934번 방문했지만 Random 액세스가 688번만 발생한 이유는 버퍼 Pinning 효과
    * 클러스터링 팩터 (인덱스 레코드가 가리키는 테이블 rowid 정렬 순서가 인덱스 키 값 정렬 순서와 일치하는 정도를 말한다)가 좋을수록 버퍼 Pinning에 의한 블록 I/O 감소 효과가 커진다
* 결과
  * 최종 한 건의 결과집합을 만들어 내기 위해서 너무나 많은 Random 액세스 (688)가 발생
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```
* 인덱스 단계에서 필터링할 수 있도록 인덱스에 (object_name)를 추가한 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=4 ...)
    * 1 | INDEX RANGE SCAN T_IDX (cr=3)
* 분석
  * 인덱스에서 1건 출력했기 때문에, 테이블을 1번 방문한다
  * 실제 발생한 Random 액세스도 1(4-3)건
* 결과
  * 동일한 SELECT문에 인덱스 구성 변경으로 테이블 Random 액세스 감소
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner, object_name);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```

<br>
<hr>
<br>

## Memory vs. Disk IO
#### 

<br>

### IO 효율화 튜닝의 중요성
* 모든 DBMS는 버퍼 캐시를 경유해 I/O를 수행한다
  * 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고, 찾지 못할 때만 디스크에서 읽는 것
  * 버퍼 캐시는 유한한 메모리 자원을 효율적으로 사용하기 위해서 자주 액세스하는 블록들이 캐시에 더 오래 남아 있도록 LRU 알고리즘 사용

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/806f944f-891e-4449-bf02-000d6d389454">
</div>

* 물리적인 Disk I/O가 필요할 때는 서버 프로세스는 I/O 서브시스템에 I/O Call을 발생시키고 잠시 대기하게 되면서 비용이 커진다
  * 디스크에 발생하는 경합이 심할수록 대기 시간도 길어진다

<br>

### 버퍼 캐시 히트율 (Buffer Cache Hit Ratio - BCHR)
* BCHR 공식 - 물리적인 디스크 읽기를 수반하지 않고 곧바로 메모리에서 블록을 찾은 비율
  * (캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) * 100
  * ( (논리적 블록읽기 - 물리적 블록읽기) / 논리적 블록읽기) * 100
  * ( 1 - (물리적 블록읽기) ) / (논리적 블록읽기) ) * 100
* 용어
  * 논리적 블록읽기 = 총 읽은 블록 수
  * 캐시에서 곧바로 찾은 블록 수 = 논리적 블록읽기 - 물리적 블록읽기
* Direct Path Read 방식으로 읽는 경우를 제외하고, 모든 블록 읽기는 버퍼 캐시를 통해 이루어진다. 즉, 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고 없을 때 디스크로부터 읽어들이며, 이때도 디스크로부터 곧바로 읽는 게 아니라 먼저 버퍼 캐시에 적재한 후에 읽는다
  * 무조건 버퍼 캐시에서 읽기 때문에 해당 방식으로 읽은 총 블록 수는 `논리적 블록읽기`
  * 따라서, 논리적 블록읽기 이후에 버퍼캐시에 원하는 블록이 없으면 물리적 물록읽기가 발생하기 때문에, 디스크를 동반하지 않은 버퍼캐시 읽기를 위하기 위해서는 `논리적 블록읽기 (Logical Reads)` - `물리적 블록읽기 (Physical Reads)`를 해줘야 한다
* SQL Trace 적용 예시)
  * 물리적 읽기 : Disk
  * 논리적 읽기 : Query + Current
  * BCHR (56%)
    * (1 - (Disk / ( Query + Current ))) * 100
    * (1 - (601,458 / (1,351,677 + 0))) * 100
    * 55.5%
  * 분석
    * 논리적으로 100개 블록 읽기 요청 => 56개는 메모리에서 바로 가져가기 + 44개는 디스크에서 가져오기
    * 다른 대기 이벤트가 없었다면 CPU Time과 Elapsed Time 간에 발생한 시간차는 대부분 디스크 I/O 때문
  * 결과
    * 논리적인 블록 요청 횟수를 줄이고, 물리적으로 디스크에서 읽어야할 블록 수를 줄이거는 것이 I/O 튜닝의 핵심 원리
    * BCHR의 결과 %는 높이고, 계산식에 사용하는 블록 I/O 값 자체도 낮은 값으로 유지하는 것이 좋다
      * 작은 테이블을 자주 액세스하면 모든 블록이 메모리에서 찾아져서 BCHR은 높지만 블록을 찾는 과정에서 래치를 얻어야 하므로 의외로 큰 비용을 수반한다
      * 특히, 같은 블록을 여러 세션이 동시에 액세스함으로 인해 래치 경합과 버퍼 Lock 경합까지 발생한다면 메모리 I/O 비용이 오히려 디스크 I/O 이상으로 커질 수 있다
      * 따라서, BCHR이 100%라고 하더라도 논리적으로 읽어야 할 블록 수의 절대량이 많다면 반드시 SQL 튜닝을 실시해서 논리적인 블록 읽기를 최소화해야 한다
      * 예) 대량의 데이터를 기준으로 NL 조인 방식을 사용해 작은 테이블을 반복적으로 Lookup 하는 경우가 대표적
 
<br>

### 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향
* 메모리 I/O와 디스크 I/O 발생량뿐만 아니라, 최근에는 네트워크 속도가 I/O 성능에 지대한 영향을 미치고 있다
* 이제는 데이터베이스 서버와 스토리지 간에 NAS 서버나 SAN을 통해 연결되는 아키텍처를 사용한다
  * 예전에는 서버에 전용 케이블로 직접 연결된 외장형 저장 장치를 사용했다고 한다
* 오라클 RAC에서는 인스턴스끼리 네트워크를 통해 캐시된 블록들을 서로 공유하므로 메모리 I/O 성능에도 네트워크 속도가 지대한 영향을 미치게 되었다
  * 다른 RAC 노드에서 네트워크를 통해 전송 받은 논리적 블록 읽기가 존재하기 때문
* 디스크 속도가 문제이든, SAN이 문제이든, RAC 인터커넥트가 문제이든 I/O 성능에 관한 가장 확실하고 근본적인 해결책은 논리적인 블록 요청 횟수를 최소화하는 것

<br>
<hr>
<br>

## Single Block vs. Multiblock I/O
#### 읽고자 하는 블록을 버퍼 캐시에서 찾지 못했을 때, I/O Call을 통해 데이터파일로부터 버퍼 캐시에 적재하는 방식 = 크게 {Single Block I/O, Multiblock I/O}

<br>

### Single Block vs. Multiblock I/O
* Single Block I/O
  * 한번의 I/O Call에 하나의 데이터 블록만 읽어 메모리에 적재하는 것
  * ex) 인덱스를 통해 테이블을 액세스할 때는, 기본적으로 인덱스와 테이블 블록 모두 이 방식을 사용
* Multiblock I/O 
  * 인접한 블록들을 같이 읽어 메모리에 적재하는 것
  * 오라클 블록 사이즈에 상관없이 OS 단에서는 보통 1MB(=1,024KB) 단위로 I/O 수행
  * ex) I/O가 1MB 크기만큼 발생하니, Table Full Scan처럼 물리적으로 저장된 순서에 따라 읽을 때는 I/O 크기 범위 내에서 인접한 블록들을 같이 읽는 것이 유리
    * `인접한 블록` : 한 익스텐트 (extent) 내에 속한 블록
* 인덱스 스캔은 왜 한 블록씩 읽을까?
  * 인덱스 블록간 논리적 순서는 물리적으로 데이터파일에 저장된 순서와 다르다
  * 인덱스 리프 블록끼리 이중 연결 리스트 (Double Linked List)구조로 연결되어 있다
  * 물리적으로 한 익스텐트에 속한 블록들을 I/O Call 발생 시점에 같이 적재해 올렸는데, 그 블록들이 논리적 순서로 한참 뒤쪽에 위치할 수 있다
    * LRU 알고리즘에 의해 실제로 상용되지 못하고 버퍼에서 밀려날 수 있다
  * Index Range Scan 및 Index Full Scan 모두 논리적인 순서에 따라 Single Block I/O 방식으로 읽는다
    * Index Fast Full Scan은 Table Full Scan과 마찬가지로 Multiblock I/O 방식 사용
* 대기 이벤트
  * 서버 프로세스는 디스크에서 블록을 읽어야 하는 시점마다 I/O 서브시스템에 I/O요청하고 대기 상태에 빠진다
  * db file sequential read 대기 이벤트 : Single Block I/O 케이스
  * db file scattered read 대기 이벤트 : Multiblock I/O 케이스
* Sequential I/O 예시)
  * db file sequential read
```sql
CREATE TABLE t 
AS 
SELECT * FROM ALL_OBJECTS;

ALTER TABLE t 
ADD constraint t_pk PRIMARY KEY(object_id);

SELECT /*+ index(t) */ count(*)
FROM   t WHERE object_id > 0;
```
* Multiblock I/O 예시)
  * db file scattered read
```sql
CREATE TABLE t 
AS 
SELECT * FROM ALL_OBJECTS;

ALTER TABLE t 
ADD constraint t_pk PRIMARY KEY(object_id);

SELECT /*+ index_ffs(t) */ count(*)
FROM   t WHERE object_id > 0;
```
* Oracle 10g부터
  * Table Full Scan에 더불어, Index Range Scan 또는 Index Full Scan에서 테이블 액세스 없이 인덱스만 읽고 처리할 때 Multiblock I/O 방식으로 읽을 때가 있다
    * Multiblock I/O 방식으로 읽힌 블록은 LRU 리스트상 LRU 쪽에 연결된다
  * 인덱스를 스캔하면서 테이블을 Random 액세스할 때는 모두 Single Block I/O 방식으로 읽는다
    * Single Block I/O 방식으로 읽힌 블록은 LRU 리스트상 MRU 쪽에 연결된다

<br>
<hr>
<br>

## Prefetch
#### Prefetch = {테이블 Prefetch, 인덱스 Prefetch}

<br>

### Prefetch
* 오라클을 포함한 모든 DBMS는 디스크 블록을 읽을 때 곧이어 읽을 가능성이 높은 블록을 미리 읽어오는 Prefetch 기능을 제공
* Prefetch는 한 번에 여러 Single Block I/O를 동시에 수행하는 것
  * Multiblock I/O는 한 번의 I/O Call로 서로 인접한 (Contiguous) 블록, 서로 같은 익스텐트에 위치한 블록을 읽어 적재하는 것
  * 테이블 Prefetch와 인덱스 Prefetch는 인접하지 않는 (Noncontiguous) 블록, 서로 다른 익스텐트에 위치한 블록을 배치 (Batch) 방식으로 미리 적재하는 것
* CKPT 프로세스 : Prefetch된 블록들을 모니터링하는 기능
  * 곧 읽을 가능성이 높은 블록들을 미래 적재했을 때만 성능 향상에 도움을 준다
* 대기 이벤트
  * 서버 프로세스가 어차피 대기 상태에서 잠시 쉬어야 하므로, 곧이어 읽을 가능성이 높은 블록들을 버퍼 캐시에 미리 적재놓는다면, 대기 이벤트 발생횟수를 그만큼 줄일 수 있다
  * db file parallel read 대기 이벤트
 
<br>

### 인덱스 Prefetch

<div align="center">
 <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/5124f0a3-d634-4878-a320-b98df0133b97" >
</div>

* 브랜치 블록에서 앞으로 읽게 될 리프 블록 주소를 미리 얻을 수 있으므로 I/O Call이 필요한 시점에 미리 캐싱해 두는 것이 가능하다
* Index Range Scan : (1) => (2) => (3) => (4) 순 액세스
  * 5번 리프 블록을 디스크에서 읽어야 하면, 6번 리프 블록까지 같이 읽어서 버퍼 캐시에 적재해두면 (4)번 리프 블록 스캔이 진행되는 동안 디스크 I/O 때문에 대기할 가능성 감소
* Index Full Scan에서도 큰 효율성을 보인다
* Sequential 액세스 성능 향상을 위해 Multiblock I/O와 인덱스 Prefetch 기능 사용
* 인덱스 Fetch 제어 파라미터
  * _index_prefetch_factor
  * _db_file_noncontig_mblock_read_count

<br>

### 테이블 Prefetch

<div align="center">
 <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/509dda34-1205-4972-b7ab-91e9035f41b8" >
</div>

* 인덱스를 경유해 테이블 레코드를 액세스하는 도중 디스크에서 캐시로 블록을 적재해야 하는 상황이 발생할 수 있는데, 그때 다른 테이블 블록까지 미리 적재해 두는 기능이다
* Random 액세스 성능 향상을 위해 버퍼 Pinning과 테이블 Prefetch 기능 사용
  * 버퍼 Pinning : Random 액세스에 의한 논리적 블록 요청 횟수 감소
  * 테이블 Prefetch : 디스크 I/O에 의한 대기 횟수 감소
* 테이블 Fetch 제어 파라미터
  * _table_lookup_prefetch_size
  * _table_lookup_prefetch_thresh
  * _multi_join_key_table_lookup
* `클러스터링 팩터`가 나쁠 때 디스크 I/O가 더 발생하게 되기 때문에 큰 효율성을 보인다
* DB2, SQL Server 등도 데이터 블록 Prefetch 기능이 있지만 구현 방식이 다르다
  * DB2의 경우, 4~11번까지 리프 블록을 먼저 스캔한 이후에 결과 집합을 rowid 순으로 정렬한 후에 테이블 액세스를 시작한다
  * 정렬된 rowid 순서대로 테이블 블록을 접근하기 때문에, 각 테이블 블록을 한 번씩만 액세스하게 된다
    * 각 블록에 한 번 접근했을 때 필요한 모든 레코드를 모두 읽기 때문에 Random 액세스의 비효율을 완전히 제거 가능
  * 오라클의 경우에도, 클러스터링 팩터가 높은 인덱스를 이용할 때 테이블 Random 액세스를 최소화할 수 있다

<br>
<hr>
<br>

## Direct Path I/O
#### 버퍼 캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct Path I/O 기능 제공

<br>

### Direct Path I/O
* 일반적인 블록 I/O는 DB 버퍼 캐시를 경유
  * 데이터 읽기 : 버퍼 캐시에 적재된 블록에서 확인 후 없으면 디스크에서 조회
  * 데이터 변경 : 버퍼 캐시에 적재된 블록에서 변경 후 DBWR 프로세스가 주기적으로 Dirty 버퍼 블록들을 데이터파일에 기록
* 다만, 재사용 가능성이 없는 임시 세그먼트 블록들을 읽고 쓸 때도 버퍼 캐시를 경유할 필요는 없다
  * 이런 경우, 곧바로 디스크로 진입하는 Direct Path I/O 기능 사용

<br>

### Direct Path Read/Write Temp

<div align="center">
  <img width="80%" src="https://github.com/PoSungKim/development_study/assets/37537227/f708ca7d-0498-4df3-9f02-b5ba07c068fd" >
</div>

* 데이터 정렬할 때 PGA 메모리에 할당되는 Sort Area 이용
* 하지만, Sort Area가 부족하면, Temp 테이블스페이스 이용
  * 이때, Temp 테이블스페이스에 쓰기 (정렬)/읽기 할 때 Direct Path I/O 방식 사용
* I/O Call 대기 이벤트
  * Direct Path Write Temp
  * Direct Path Read Temp

<br>
<hr>
<br>
