# IO 효율화 원리
> 데이터베이스 성능 튜닝의 3대 핵심 요소 (라이브러리 캐시 최적화, 데이터베이스 Call 최소화, I/O 효율화 및 버퍼캐시 최적화)
* I/O 효율화 및 버퍼캐시 최적화 : 인덱스 원리, 조인 원리, 옵티마이저 원리에 대한 이해가 필수

<hr>
<br>

## 블록 단위 IO
#### 오라클을 포함한 모든 DBMS는 블록 (Block) 단위로 버퍼 캐시 IO 및 데이터 파일 IO 발생 (** 타 DBMS에서는 페이지 (Page)라는 용어로 표현)
#### SQL 성능을 좌우하는 가장 중요한 성능지표는 액세스하는 블록 개수이며, 옵티마이저의 판단에 가장 큰 영향을 미치는 것도 액세스해야 하는 블록 개수 (Full Table Scan vs Index Scan)

<br>

### 블록 단위 IO
* 액세스
  * Sequential Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 모든 레코드를 순차적으로 읽는 패턴
  * Random Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 한 건의 레코드만 읽을 수도 있는 패턴
* 블록 단위 IO
  * 메모리 버퍼 캐시에서 블록을 읽고 쓸 때
  * 데이터파일에 저장된 데이터 블록을 직접 읽거나 쓸 때 (Direct Path I/O)
  * 데이터파일에서 DB 버퍼 캐시로 블록을 적재할 때 : Single Block Read 또는 Multiblock Read 방식을 사용
  * 버퍼 캐시에서 변경된 블록을 다시 데이터파일에 저장할 때 : Dirty 버퍼를 주기적으로 데이터파일에 기록하는 것을 말하며, DBWR 프로세스에 의해 수행된다. 성능 향상을 위해 한 번에 여러 블록씩 처리한다
* 딕셔너리 캐시는 Row 단위 IO
* 오라클에서 허용하는 블록 크기 (db_block_size) : 2,4,8,16,32,64K
  * 다른 크기의 블록을 사용하기 위해서는 별도의 테이블스페이스 및 버퍼 Pool 구성 필요

<br>

### Sequential vs. Random 액세스

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/039ddd54-85b6-45a6-8f7c-b92946318a75">
</div>

* Sequential Access
  * 의미 : 레코드간 논리적 도는 물리적인 순서를 따라 차례대로 읽어 나가는 방식
    * 인덱스 리프 블록에 위치한 모든 레코드는 포인터를 따라 논리적으로 연결되어 있어서, 이 포인터를 따라 스캔하는 방식도 Sequential Access
    * 테이블 레코드 간에는 포인터로 연결되어 있지는 않지만 테이블 스캔할 때는 물리적으로 저장된 순서대로 읽어 나가므로 해당 방식도 Sequential Access
  * 성능 향상 방법
    * Multiblock I/O, 인덱스 Prefetch
* Random Access
  * 의미 : 레코드간 논리적, 물리적 순서를 따르지 않고, 한 건을 읽기 위해 한 블록씩 접근하는 방식
    * 주로 (4), (6)에서 성능 저하 발생
    * 하지만, NL조인의 Inner Table 액세스를 위한 (1), (2), (3)에서도 성능 저하 영향 발생 가능
  * 성능 향상 방법
    * 버퍼 Pinning, 테이블 Prefetch
* Sequential 액세스가 항상 Random Access보다 효율적인 것은 아니다
  * Seuqential 액세스의 경우, 선택도가 중요
    * 선택도 : 총 읽은 레코드에서 결과 집합으로 선택되는 비중
    * ex) Sequential Access로 100개를 읽었어도 그 중 99개를 버리고 1개의 결과 집합만 취한다면 Random Access보다 나을 것이 없다
* I/O 튜닝의 핵심 원리
  * Sequential 액세스의 선택도 (Selectivity)를 높인다
  * Random 액세스 발생량을 줄인다
 
<br>

### Sequential 액세스 선택도 높이기
* 49,906건이 담긴 테이블 (t))
```sql
CREATE TABLE t 
AS
SELECT * FROM all_objects
ORDER BY dbms_random.value;
```
* 24,613건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (49%) => 나쁘지 않은 Table Full Scan 효율성)
  * 읽은 블록 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'; 
```
* 1건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (0.002%) => 매우 낮은 Table Full Scan 효율성)
  * 읽은 블록 (CR) 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```
* 테이블 스캔 후 읽은 레코드들이 대부분 필터링되어 일부만 선택된다면 인덱스 사용이 더 효율적)
  * 1건의 결과집합 (INDEX RANGE SCAN T_IDX)
  * 읽은 블록 (CR) 76개
```sql
CREATE INDEX t_index ON t(owner, object_name);

SELECT  /*+ index(t t_idx) */ count(*) FROM t
WHERE   owner LIKE 'SYS%'
AND     object_name = 'ALL_OBJECTS';
```
* 인덱스로 읽은 레코드 개수 계산 예시)
  * 14,587건 Index Scan => 선택도 (0.007%) => Index Scan (Sequential Access)에서 비효율성 발생 가능
  * 인덱스 스캔도 충분히 비효율성이 발생 가능하다는 점을 인지해야함
    * 인덱스는 테이블과 달리 정렬된 순서를 유지하므로 일정 범위를 읽다가 멈출 수 있다는 점만 다르다
    * 다만, 인덱스 스캔의 효율은 조건절에 사용된 컬럼과 연산자 형태, 인덱스 구성에 의해 영향을 받는다
```sql
SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    ((owner = 'SYS' AND object_name >= 'ALL_OBJECTS') or (owner > 'SYS'));
```
* 인덱스 칼럼 순서를 변경한 예시)
  * from (owner, object_name) => to (object_name, owner)
  * 읽은 블록 (CR) 2개 
    * 인덱스 루트 블록 1개 + 리프 블록 1개
  * 1건의 결과집합 + 1건 INDEX RANGE SCAN T_IDX (정확히는 One-plus 스캔까지 2건) => 선택도 (100%) => 효율적인 Index Scan (Sequential Access) 발생
```sql
DROP INDEX t_idx;
CREATE INDEX t_index ON t(object_name, owner);

SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```

<br>

### Random 액세스 발생량 줄이기
* 인덱스에 속하지 않는 칼럼 (object_id)을 참조하도록 쿼리를 변경함으로써 테이블 액세스 발생하는 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=739 ...)
    * 22934 | INDEX RANGE SCAN T_IDX (cr=51)
* 분석
  * 22,934 번만큼 테이블 방문 + 688 (739 - 51) 블록을 Random 액세스
  * 테이블을 22,934번만큼 방문하면서 내부적으로 22,934번 방문했지만 Random 액세스가 688번만 발생한 이유는 버퍼 Pinning 효과
    * 클러스터링 팩터 (인덱스 레코드가 가리키는 테이블 rowid 정렬 순서가 인덱스 키 값 정렬 순서와 일치하는 정도를 말한다)가 좋을수록 버퍼 Pinning에 의한 블록 I/O 감소 효과가 커진다
* 결과
  * 최종 한 건의 결과집합을 만들어 내기 위해서 너무나 많은 Random 액세스 (688)가 발생
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```
* 인덱스 단계에서 필터링할 수 있도록 인덱스에 (object_name)를 추가한 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=4 ...)
    * 1 | INDEX RANGE SCAN T_IDX (cr=3)
* 분석
  * 인덱스에서 1건 출력했기 때문에, 테이블을 1번 방문한다
  * 실제 발생한 Random 액세스도 1(4-3)건
* 결과
  * 동일한 SELECT문에 인덱스 구성 변경으로 테이블 Random 액세스 감소
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner, object_name);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```

<br>
<hr>
<br>

## Memory vs. Disk IO
#### 

<br>

### IO 효율화 튜닝의 중요성
* 모든 DBMS는 버퍼 캐시를 경유해 I/O를 수행한다
  * 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고, 찾지 못할 때만 디스크에서 읽는 것
  * 버퍼 캐시는 유한한 메모리 자원을 효율적으로 사용하기 위해서 자주 액세스하는 블록들이 캐시에 더 오래 남아 있도록 LRU 알고리즘 사용

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/806f944f-891e-4449-bf02-000d6d389454">
</div>

* 물리적인 Disk I/O가 필요할 때는 서버 프로세스는 I/O 서브시스템에 I/O Call을 발생시키고 잠시 대기하게 되면서 비용이 커진다
  * 디스크에 발생하는 경합이 심할수록 대기 시간도 길어진다

<br>

### 버퍼 캐시 히트율 (Buffer Cache Hit Ratio - BCHR)
* BCHR 공식 - 물리적인 디스크 읽기를 수반하지 않고 곧바로 메모리에서 블록을 찾은 비율
  * (캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) * 100
  * ( (논리적 블록읽기 - 물리적 블록읽기) / 논리적 블록읽기) * 100
  * ( 1 - (물리적 블록읽기) ) / (논리적 블록읽기) ) * 100
* 용어
  * 논리적 블록읽기 = 총 읽은 블록 수
  * 캐시에서 곧바로 찾은 블록 수 = 논리적 블록읽기 - 물리적 블록읽기
* Direct Path Read 방식으로 읽는 경우를 제외하고, 모든 블록 읽기는 버퍼 캐시를 통해 이루어진다. 즉, 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고 없을 때 디스크로부터 읽어들이며, 이때도 디스크로부터 곧바로 읽는 게 아니라 먼저 버퍼 캐시에 적재한 후에 읽는다
  * 무조건 버퍼 캐시에서 읽기 때문에 해당 방식으로 읽은 총 블록 수는 `논리적 블록읽기`
  * 따라서, 논리적 블록읽기 이후에 버퍼캐시에 원하는 블록이 없으면 물리적 물록읽기가 발생하기 때문에, 디스크를 동반하지 않은 버퍼캐시 읽기를 위하기 위해서는 `논리적 블록읽기 (Logical Reads)` - `물리적 블록읽기 (Physical Reads)`를 해줘야 한다
* SQL Trace 적용 예시)
  * 물리적 읽기 : Disk
  * 논리적 읽기 : Query + Current
  * BCHR (56%)
    * (1 - (Disk / ( Query + Current ))) * 100
    * (1 - (601,458 / (1,351,677 + 0))) * 100
    * 55.5%
  * 분석
    * 논리적으로 100개 블록 읽기 요청 => 56개는 메모리에서 바로 가져가기 + 44개는 디스크에서 가져오기
    * 다른 대기 이벤트가 없었다면 CPU Time과 Elapsed Time 간에 발생한 시간차는 대부분 디스크 I/O 때문
  * 결과
    * 논리적인 블록 요청 횟수를 줄이고, 물리적으로 디스크에서 읽어야할 블록 수를 줄이거는 것이 I/O 튜닝의 핵심 원리
    * BCHR의 결과 %는 높이고, 계산식에 사용하는 블록 I/O 값 자체도 낮은 값으로 유지하는 것이 좋다
      * 작은 테이블을 자주 액세스하면 모든 블록이 메모리에서 찾아져서 BCHR은 높지만 블록을 찾는 과정에서 래치를 얻어야 하므로 의외로 큰 비용을 수반한다
      * 특히, 같은 블록을 여러 세션이 동시에 액세스함으로 인해 래치 경합과 버퍼 Lock 경합까지 발생한다면 메모리 I/O 비용이 오히려 디스크 I/O 이상으로 커질 수 있다
      * 따라서, BCHR이 100%라고 하더라도 논리적으로 읽어야 할 블록 수의 절대량이 많다면 반드시 SQL 튜닝을 실시해서 논리적인 블록 읽기를 최소화해야 한다
      * 예) 대량의 데이터를 기준으로 NL 조인 방식을 사용해 작은 테이블을 반복적으로 Lookup 하는 경우가 대표적
 
<br>

### 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향
* 메모리 I/O와 디스크 I/O 발생량뿐만 아니라, 최근에는 네트워크 속도가 I/O 성능에 지대한 영향을 미치고 있다
* 이제는 데이터베이스 서버와 스토리지 간에 NAS 서버나 SAN을 통해 연결되는 아키텍처를 사용한다
  * 예전에는 서버에 전용 케이블로 직접 연결된 외장형 저장 장치를 사용했다고 한다
* 오라클 RAC에서는 인스턴스끼리 네트워크를 통해 캐시된 블록들을 서로 공유하므로 메모리 I/O 성능에도 네트워크 속도가 지대한 영향을 미치게 되었다
  * 다른 RAC 노드에서 네트워크를 통해 전송 받은 논리적 블록 읽기가 존재하기 때문
* 디스크 속도가 문제이든, SAN이 문제이든, RAC 인터커넥트가 문제이든 I/O 성능에 관한 가장 확실하고 근본적인 해결책은 논리적인 블록 요청 횟수를 최소화하는 것

<br>
<hr>
<br>

## Single Block vs. Multiblock I/O
#### 읽고자 하는 블록을 버퍼 캐시에서 찾지 못했을 때, I/O Call을 통해 데이터파일로부터 버퍼 캐시에 적재하는 방식 = 크게 {Single Block I/O, Multiblock I/O}

<br>

### Single Block vs. Multiblock I/O
* Single Block I/O
  * 한번의 I/O Call에 하나의 데이터 블록만 읽어 메모리에 적재하는 것
  * ex) 인덱스를 통해 테이블을 액세스할 때는, 기본적으로 인덱스와 테이블 블록 모두 이 방식을 사용
* Multiblock I/O 
  * 인접한 블록들을 같이 읽어 메모리에 적재하는 것
  * 오라클 블록 사이즈에 상관없이 OS 단에서는 보통 1MB(=1,024KB) 단위로 I/O 수행
  * ex) I/O가 1MB 크기만큼 발생하니, Table Full Scan처럼 물리적으로 저장된 순서에 따라 읽을 때는 I/O 크기 범위 내에서 인접한 블록들을 같이 읽는 것이 유리
    * `인접한 블록` : 한 익스텐트 (extent) 내에 속한 블록
* 인덱스 스캔은 왜 한 블록씩 읽을까?
  * 인덱스 블록간 논리적 순서는 물리적으로 데이터파일에 저장된 순서와 다르다
  * 인덱스 리프 블록끼리 이중 연결 리스트 (Double Linked List)구조로 연결되어 있다
  * 물리적으로 한 익스텐트에 속한 블록들을 I/O Call 발생 시점에 같이 적재해 올렸는데, 그 블록들이 논리적 순서로 한참 뒤쪽에 위치할 수 있다
    * LRU 알고리즘에 의해 실제로 상용되지 못하고 버퍼에서 밀려날 수 있다
  * Index Range Scan 및 Index Full Scan 모두 논리적인 순서에 따라 Single Block I/O 방식으로 읽는다
    * Index Fast Full Scan은 Table Full Scan과 마찬가지로 Multiblock I/O 방식 사용
* 대기 이벤트
  * 서버 프로세스는 디스크에서 블록을 읽어야 하는 시점마다 I/O 서브시스템에 I/O요청하고 대기 상태에 빠진다
  * db file sequential read 대기 이벤트 : Single Block I/O 케이스
  * db file scattered read 대기 이벤트 : Multiblock I/O 케이스
* Sequential I/O 예시)
  * db file sequential read
```sql
CREATE TABLE t 
AS 
SELECT * FROM ALL_OBJECTS;

ALTER TABLE t 
ADD constraint t_pk PRIMARY KEY(object_id);

SELECT /*+ index(t) */ count(*)
FROM   t WHERE object_id > 0;
```
* Multiblock I/O 예시)
  * db file scattered read
```sql
CREATE TABLE t 
AS 
SELECT * FROM ALL_OBJECTS;

ALTER TABLE t 
ADD constraint t_pk PRIMARY KEY(object_id);

SELECT /*+ index_ffs(t) */ count(*)
FROM   t WHERE object_id > 0;
```
* Oracle 10g부터
  * Table Full Scan에 더불어, Index Range Scan 또는 Index Full Scan에서 테이블 액세스 없이 인덱스만 읽고 처리할 때 Multiblock I/O 방식으로 읽을 때가 있다
    * Multiblock I/O 방식으로 읽힌 블록은 LRU 리스트상 LRU 쪽에 연결된다
  * 인덱스를 스캔하면서 테이블을 Random 액세스할 때는 모두 Single Block I/O 방식으로 읽는다
    * Single Block I/O 방식으로 읽힌 블록은 LRU 리스트상 MRU 쪽에 연결된다

<br>
<hr>
<br>

## Prefetch
#### Prefetch = {테이블 Prefetch, 인덱스 Prefetch}

<br>

### Prefetch
* 오라클을 포함한 모든 DBMS는 디스크 블록을 읽을 때 곧이어 읽을 가능성이 높은 블록을 미리 읽어오는 Prefetch 기능을 제공
* Prefetch는 한 번에 여러 Single Block I/O를 동시에 수행하는 것
  * Multiblock I/O는 한 번의 I/O Call로 서로 인접한 (Contiguous) 블록, 서로 같은 익스텐트에 위치한 블록을 읽어 적재하는 것
  * 테이블 Prefetch와 인덱스 Prefetch는 인접하지 않는 (Noncontiguous) 블록, 서로 다른 익스텐트에 위치한 블록을 배치 (Batch) 방식으로 미리 적재하는 것
* CKPT 프로세스 : Prefetch된 블록들을 모니터링하는 기능
  * 곧 읽을 가능성이 높은 블록들을 미래 적재했을 때만 성능 향상에 도움을 준다
* 대기 이벤트
  * 서버 프로세스가 어차피 대기 상태에서 잠시 쉬어야 하므로, 곧이어 읽을 가능성이 높은 블록들을 버퍼 캐시에 미리 적재놓는다면, 대기 이벤트 발생횟수를 그만큼 줄일 수 있다
  * db file parallel read 대기 이벤트
 
<br>

### 인덱스 Prefetch

<div align="center">
 <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/5124f0a3-d634-4878-a320-b98df0133b97" >
</div>

* 브랜치 블록에서 앞으로 읽게 될 리프 블록 주소를 미리 얻을 수 있으므로 I/O Call이 필요한 시점에 미리 캐싱해 두는 것이 가능하다
* Index Range Scan : (1) => (2) => (3) => (4) 순 액세스
  * 5번 리프 블록을 디스크에서 읽어야 하면, 6번 리프 블록까지 같이 읽어서 버퍼 캐시에 적재해두면 (4)번 리프 블록 스캔이 진행되는 동안 디스크 I/O 때문에 대기할 가능성 감소
* Index Full Scan에서도 큰 효율성을 보인다
* Sequential 액세스 성능 향상을 위해 Multiblock I/O와 인덱스 Prefetch 기능 사용
* 인덱스 Fetch 제어 파라미터
  * _index_prefetch_factor
  * _db_file_noncontig_mblock_read_count

<br>

### 테이블 Prefetch

<div align="center">
 <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/509dda34-1205-4972-b7ab-91e9035f41b8" >
</div>

* 인덱스를 경유해 테이블 레코드를 액세스하는 도중 디스크에서 캐시로 블록을 적재해야 하는 상황이 발생할 수 있는데, 그때 다른 테이블 블록까지 미리 적재해 두는 기능이다
* Random 액세스 성능 향상을 위해 버퍼 Pinning과 테이블 Prefetch 기능 사용
  * 버퍼 Pinning : Random 액세스에 의한 논리적 블록 요청 횟수 감소
  * 테이블 Prefetch : 디스크 I/O에 의한 대기 횟수 감소
* 테이블 Fetch 제어 파라미터
  * _table_lookup_prefetch_size
  * _table_lookup_prefetch_thresh
  * _multi_join_key_table_lookup
* `클러스터링 팩터`가 나쁠 때 디스크 I/O가 더 발생하게 되기 때문에 큰 효율성을 보인다
* DB2, SQL Server 등도 데이터 블록 Prefetch 기능이 있지만 구현 방식이 다르다
  * DB2의 경우, 4~11번까지 리프 블록을 먼저 스캔한 이후에 결과 집합을 rowid 순으로 정렬한 후에 테이블 액세스를 시작한다
  * 정렬된 rowid 순서대로 테이블 블록을 접근하기 때문에, 각 테이블 블록을 한 번씩만 액세스하게 된다
    * 각 블록에 한 번 접근했을 때 필요한 모든 레코드를 모두 읽기 때문에 Random 액세스의 비효율을 완전히 제거 가능
  * 오라클의 경우에도, 클러스터링 팩터가 높은 인덱스를 이용할 때 테이블 Random 액세스를 최소화할 수 있다

<br>
<hr>
<br>

## Direct Path I/O
#### 버퍼 캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct Path I/O 기능 제공

<br>

### Direct Path I/O
* 일반적인 블록 I/O는 DB 버퍼 캐시를 경유
  * 데이터 읽기 : 버퍼 캐시에 적재된 블록에서 확인 후 없으면 디스크에서 조회
  * 데이터 변경 : 버퍼 캐시에 적재된 블록에서 변경 후 DBWR 프로세스가 주기적으로 Dirty 버퍼 블록들을 데이터파일에 기록
* 다만, 재사용 가능성이 없는 임시 세그먼트 블록들을 읽고 쓸 때도 버퍼 캐시를 경유할 필요는 없다
  * 이런 경우, 곧바로 디스크로 진입하는 Direct Path I/O 기능 사용

<br>

### Direct Path Read/Write Temp

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/f708ca7d-0498-4df3-9f02-b5ba07c068fd" >
</div>

* 데이터 정렬할 때 PGA 메모리에 할당되는 Sort Area 이용
* 하지만, Sort Area가 부족하면, Temp 테이블스페이스 이용
  * 이때, Temp 테이블스페이스에 쓰기 (정렬)/읽기 할 때 Direct Path I/O 방식 사용
* I/O Call 대기 이벤트
  * Direct Path Write Temp
  * Direct Path Read Temp

<br>

### Direct Path Read
* 병렬 쿼리로 Full Scan을 수행할 때도 Direct Path Read 방식을 사용
  * 곧바로 Disk에서 읽어오면 메모리의 Dirty 버퍼를 해소하지 못하기 때문에 메모리와 디스크간 동기화 선행 필요
* 대기 이벤트
  * Direct Path Read

<br>

### Direct Path Write
* 병렬로 DML을 수행하거나 Direct Path Insert 방식으로 데이터를 insert할 때 사용
* Direct Path Insert 방식
  * insert ... select 문장에 /*+ append */ 힌트 사용
  * 병렬 모드로 insert
  * direct 옵션을 지정하고 SQL*Loader로 데이터를 로드
  * CTAS (create table ... as select)문장을 수행
* 대기 이벤트
  * Direct Path Write
* 일반적인 (Conventional) Insert 시에는 Freelist를 통해 데이터를 삽입할 블록을 할당받는다
  * Freelist를 조회하면서 Random 액세스 방식으로 버퍼 캐시에서 해당 블록을 찾고, 없으면 데이터파일에서 읽어 캐시에 적재한 후에 데이터를 삽입하므로 대량의 데이터를 insert 할 때 매우 느리다
* Direct Path Insert 시에는 Freelist를 참조하지 않고 테이블 세그먼트 또는 각 파티션 세그먼트의 HWM (High-Water Mark) 바깥 영역에 데이터를 순차적으로 입력
  * HWM 바깥 영역에 데이터를 입력하므로 Undo 발생량도 최소화한다 (Undo 데이터를 제공하지 않아도 됌)
  * Redo로그까지 최소화하도록 옵션을 줄 수도 있어 더 빠른 insert가 가능하다
```sql
INSERT INTO t NOLOGGING SELECT * FROM test;
```
* 주의할 것은 Direct Path Insert 방식으로 데이터를 입력하면 Exclusive 모드 테이블 Lock이 걸린다
  * 성능은 빨라지지만 해당 테이블에 다른 트랜잭션이 DML으 수행하지 못하도록 막는다
  * 일반적인 DML 수행 시에는 Row Exclusive 모드 테이블 Lock을 사용하므로 다른 트랜잭션의 DML을 맞지 않는다=
```sql
ALTER SESSION ENABLE PARALLEL DML;
DELETE /*+ parallel(b 4) */ FROM big_table b; -- Exclusive 모드 TM Lock
```

<br>
<hr>
<br>

## RAC 캐시 퓨전
#### 데이터베이스 동시 사용자가 많을 때 부하를 분산할 목적으로 시스템마다 다양한 데이터 분산 전략 사용

<br>

### RAC 캐시 퓨전
* 데이터 분산 전략
  * 데이터베이스 서버 간 복제
    * 여러 대의 데이터베이스 서버를 두고 각 서버에서 발생한 트랜잭션 데이터를 상호 복제하는 방식
  * 업무별 수직 분할
    * 업무 영역별로 데이터베이스를 따로 두고 각각 다른 테이블을 관리하며, 다른 영역의 데이터는 분산(Remote) 쿼리를 이용해 조회하는 방식
  * 데이터 구분에 따른 수평 분할
    * 스키마는 같지만 데이터 구분에 따라 데이터베이스를 따로 가져가는 방식
* 물리적으로 분산시킨 데이터를 논리적으로 다시 톷합해 하나의 뷰를 통해 액세스하는 데이터베이스 클러스터링 기법도 나왔다
* 최근에는 데이터베이스를 다시 하나로 통합하고 이를 액세스하는 인스턴스를 여러 개두는 공유 디스크 (Shared Disk) 방식의 데이터베이스 클러스터링 기법이 도입되기 시작
  * 그 중 오라클 RAC 모델은 공유 디스크 방식에 기반을 두면서 인스턴스 간에 버퍼 캐시까지 공유 (Shared Cache)하는 캐시 퓨전 (Cache Fusion) 기술로 발전
* 버퍼 캐시를 공유하기 때문에 블록 I/O가 많아지면 성능이 취약해지는 단점이 존재
  * 여러 인스턴스 간에 동일 데이터에 대한 경합이 심해지고, 액세스를 직렬화하기 위한 추가적인 동기화 메커니즘 또한 필요
  * RAC 모델 특성상 발생하는 성능 문제들을 해결하려면 캐시 퓨전 프로세싱 원리 이해 필요
    * RAC는 글로벌 캐시 (Global Cache)
      * 클러스터링 되어 있는 모든 인스턴스 노드의 버퍼 캐시를 하나의 버퍼 캐시로 간주
      * 특정 인스턴스 노드에 없어도 다른 노드에 캐싱되어 있으면 디스크 I/O 없이 저장된 노드에서 값을 가져온다
    * 모든 데이터 블록에 대해 마스터 노드가 정해져 있다
* 캐시 퓨전 원리
  * 읽고자 하는 블록이 로컬 캐시에 없을 때 마스터 노드에 전송 요청을 한다
  * 마스터 노드는 해당 블록을 캐싱하고 있는 노드에 메세지를 보내 그 블록을 요청했던 노드에 전송하도록 지시한다
* Current 블록의 의미
  * Current 블록은 디스크로부터 읽혀진 후 사용자의 갱신사항이 반영된 최종 상태의 원본 블록을 말하며, CR 블록은 Current 블록에 대한 복사본이다
  * CR 블록은 여러 버전이 존재할 수 있지만 Current 블록은 오직 한 개뿐이다
* RAC 환경에서의 Current 블록: Shared 모드 Current (SCur) + Exclusive 모드 Current (XCur)
  * SCur 상태의 블록은 동시에 여러 노드에 캐싱될 수 있다
  * XCur 상태의 블록은 단 하나의 노드에만 존재할 수 있다
* 자주 읽히는 데이터 블록을 각 노드가 SCur 모드로 캐싱하고 있을 때 가장 효율적인 상태가 된다
  * 그 중 한 노드가 XCur 모드로 업그레이드를 요청하는 순간 다른 노드에 캐싱되어 있던 SCur 블록들은 모두 Null 모드로 다운그레이드된다 (PI (Past Image) 블록이 된다)
 
<br>

### (1) 전송 없는 읽기 : Read with No Transfer

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/f1e717d7-6eb8-40ee-ac17-cf819a761cf7" >
</div>

<br>

### (2) 읽기/읽기 전송 : Read to Read Transfer 

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/95956b3c-c6b8-4ca0-96e5-64ba26f058fd" >
</div>

<br>

### (3) 읽기/쓰기 전송 : Read to Write Transfer 

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/2f035e42-434c-44b0-aa39-44b1aac08bf9" >
</div>

<br>

### (4) 쓰기/쓰기 전송 : Write to Write Transfer

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/b76a0754-420f-45be-94c8-168869632e17" >
</div>

<br>

### (5) 쓰기/읽기 전송 : Write to Read Transfer

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/ce367972-be12-42ac-96cc-ae62d5e1bedb" >
</div>

<br>
<hr>
<br>

## Result 캐시
#### SGA의 Shared Pool에 위치

<br>

### Result 캐시
* DB 버퍼 캐시에 캐싱된 블록을 일근ㄴ 것도 때에 따라서 고비용 구조
  * 작은 테이블을 메모리 버퍼 캐시에서 읽더라도 반복 액세스가 많이 일어나면 좋은 성능을 기대하기 어렵다
* 이에 따라, 오라클은 한번 수행한 쿼리 또는 PL/SQL 함수의 결과값을 Result 캐시에 저장해 두는 기능을 11g부터 제공
  * DML이 거의 발생하지 않는 테이블을 참조하면서, 반복 수행 요청이 많은 쿼리에 이 기능을 사용하면 I/O 발생량을 현격히 감소시킬 수 있다
* Result 캐시 메모리
  * SQL Query Result 캐시
  * PL/SQL 함수 Result 캐시
* SGA의 Shared Pool에 위치하기 때문에 모든 세션에서 공유 가능하고 인스턴스를 재기동하면 초기화된다
  * 공유 자원이기 때문에 Latch 필요
    * Result Cache : Latch
    * Result Cache : SO Latch
* SQL 쿼리 Manual 힌트 예시)
  * 서버 프로세스는 힌트를 보고 Result 캐시 메모리를 보고 있으면 결과 집합 리턴; 없다면, 쿼리를 수행하여 결과를 리턴하고 Result 캐시에 적재
  * Result 캐시에 적재된 쿼리에서 사용하는 테이블에 DML이 발생하면 쿼리 결과집합은 무효화된다
```sql
SELECT /*+ RESULT_CACHE */ COL, COUNT(*)
FROM   R_CACHE_TEST
WHERE  GUBUN = 7
GROUP BY COL
```
* 쿼리 결과집합을 캐싱하지 못하는 경우
  * Dictionary 오브젝트를 참조할 때
  * Temporary 테이블을 참조할 때
  * 시퀀스부터 CURRVAL, NEXTVAL Pseudo 컬럼을 호출할 때
  * 쿼리에서 아래 SQL 함수를 사용할 때
    * CURRENT_DATE
    * CURRENT_TIMESTAMP
    * LOCAL_TIMESTAMP
    * SYS_CONTEXT
    * SYS_GUID
    * SYSDATE
    * SYSTIMESTAMP
    * USERENV
* 바인딩 변수가 있는 쿼리는 각 바인드 변수 값 별로 캐싱된다
  * 따라서, 다양한 값을 가진 바인딩 변수와 수행 빈도가 높은 쿼리가 OLTP성 쿼리이기 때문에 조심해서 사용 필요
  * 메모리가 부족해지면, LRU 알고리즘으로 필요한 공간 생성
* PL/SQL 함수 예시)
  * RELIES_ON절 대상인 테이블에 DML이 발생하면 쿼리 결과집합은 무효화된다
```sql
create or replace function get_team_name (p_team_cd number)
return varchar2
RESULT_CACHE RELIES_ON (r_cache_function)
is
  l_team_name r_cache_function.team_name%type;
begin
  select team_name into l_team_name
  from   r_cache_function
  where  team_cd = p_team_cd;
  return l_team_name;
end;
```
* 여러 쿼리 블록이 서로 연결되어 최종 결과 집합을 만들지 않고, 특정 쿼리 블록만 캐싱하는 인라인 뷰 예시)
  * 너무 자주 무효화되면 Result 캐시의 활용성이 떨어지기 때문
```sql
SELECT *
FROM   r_cache_test t1,
       ( SELECT /*+ RESULT_CACHE */ ID FROM R_CACHE_TEST2
        WHERE ID = 1 ) t2
WHERE  t1.id = t2.id;
```
```sql
WITH mv_test
AS ( SELECT /*+ RESULT_CACHE MATERIALIZE */ SUM(ID) RNUM, ID
     FROM   R_CACHE_TEST
     GROUP BY ID )
SELECT *
FROM   r_cache_test t1,
       wv_test t2
WHERE  t1.id = t2.rnum;
```
```sql
SELECT SUM(val)
FROM   ( SELECT SUM(c) val
         FROM   ext_stat_test
         UNION ALL
         SELECT /*+ RESULT_CACHE */ SUM(ID+SUM_DATA)
         FROM   R_CACHE_TEST
)
```
* where 절에 사용된 서브쿼리는 캐싱이 안되는데, 그 예시)
```sql
SELECT *
FROM   r_cache_test
WHERE  id = ( SELECT /*+ result_cache */ id
              FROM   r_cache_test2
              WHERE  id = 1 )
```
* DW뿐만 아니라 OLTP 환경에서도 효과가 높은 상황
  * 작은 결과 집합을 얻으려고 대용량 데이터를 읽어야 할 때
  * 읽기 전용의 작은 테이블을 반복적으로 읽어야 할 때
  * 읽기 전용 코드 테이블을 읽어 코드명칭을 반환하는 함수
* 아래 경우에는 Result 캐시 기능 사용 자제 필요
  * 쿼리가 참조하는 테이블에 DML이 자주 발생할 때
  * 함수 또는 바인드 변수를 가진 쿼리에서 입력되는 값의 종류가 많고, 그 값들이 골고루 입력될 때

<br>
<hr>
<br>

## I/O 효율화 원리
#### 어플리케이션 측면에서 논리적인 I/O 요청 횟수를 최소화하는 것이 I/O 효율화 튜닝의 핵심 원리

<br>

### (1) 필요한 최소 블록만 읽도록 쿼리 작성
* 논리적인 집합 재구성을 통해 읽어야 할 데이터양 최소화 가능

<br>

### (2) 최적의 옵티마이징 팩터를 제공
* 전략적인 인덱스 구성
* DBMS가 제공하는 다양한 기능 활용
  * 파티션, 클러스터, IOT, MV, FBI, 분석 함수 등 
* 옵티마이저 모드 설정
  ```sql
  create index t_idx on t(owner, created);
  
  alter session set optimizer_mode = 'ALL_ROWS';
  -- 정렬된 결과 집합 전체를 Fetch할 것이므로 Full Table Scan (Random Access 미발생)
  select * from t
  where  owner = 'SYS'
  order by created;
  
  alter session set optimizer_mode = 'FIRST_ROWS';
  -- 정렬된 결과 집합 전체에서 처음 일부 레코드만 Fetch하다가 멈출 것이므로 Index Range Scan (Sequential Access 미발생)
  select * from t
  where  owner = 'SYS'
  order by created;
  ```
* 통계정보의 중요성
  * dbms_stats.gather_table_stats
  * dbms_stats.gather_system_stats
    * CPU 속도
    * 평균적인 Single Block 읽기 속도
    * 평균적인 Multiblock 읽기 속도
    * 평균적인 Multiblock I/O 개수
 
<br>

### (3) 필요하다면, 옵티마이저 힌트를 사용해 최적의 액세스 경로로 유도
* 최적의 옵티마이징 팩터를 제공했다면 가급적 옵티마이저 판단에 맡기는 것이 바람직
* 다만, 옵티마이저가 생각만큼 최적의 실행계획을 수립하지 못하면 힌트 사용 필요


<br>
<hr>
<br>
