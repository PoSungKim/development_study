# IO 효율화 원리
> 데이터베이스 성능 튜닝의 3대 핵심 요소 (라이브러리 캐시 최적화, 데이터베이스 Call 최소화, I/O 효율화 및 버퍼캐시 최적화)
* I/O 효율화 및 버퍼캐시 최적화 : 인덱스 원리, 조인 원리, 옵티마이저 원리에 대한 이해가 필수

<hr>
<br>

## 블록 단위 IO
#### 오라클을 포함한 모든 DBMS는 블록 (Block) 단위로 버퍼 캐시 IO 및 데이터 파일 IO 발생 (** 타 DBMS에서는 페이지 (Page)라는 용어로 표현)
#### SQL 성능을 좌우하는 가장 중요한 성능지표는 액세스하는 블록 개수이며, 옵티마이저의 판단에 가장 큰 영향을 미치는 것도 액세스해야 하는 블록 개수 (Full Table Scan vs Index Scan)

<br>

### 블록 단위 IO
* 액세스
  * Sequential Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 모든 레코드를 순차적으로 읽는 패턴
  * Random Access : 하나의 블록을 액세스해 그 안에 저장돼 있는 한 건의 레코드만 읽을 수도 있는 패턴
* 블록 단위 IO
  * 메모리 버퍼 캐시에서 블록을 읽고 쓸 때
  * 데이터파일에 저장된 데이터 블록을 직접 읽거나 쓸 때 (Direct Path I/O)
  * 데이터파일에서 DB 버퍼 캐시로 블록을 적재할 때 : Single Block Read 또는 Multiblock Read 방식을 사용
  * 버퍼 캐시에서 변경된 블록을 다시 데이터파일에 저장할 때 : Dirty 버퍼를 주기적으로 데이터파일에 기록하는 것을 말하며, DBWR 프로세스에 의해 수행된다. 성능 향상을 위해 한 번에 여러 블록씩 처리한다
* 딕셔너리 캐시는 Row 단위 IO
* 오라클에서 허용하는 블록 크기 (db_block_size) : 2,4,8,16,32,64K
  * 다른 크기의 블록을 사용하기 위해서는 별도의 테이블스페이스 및 버퍼 Pool 구성 필요

<br>

### Sequential vs. Random 액세스

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/039ddd54-85b6-45a6-8f7c-b92946318a75">
</div>

* Sequential Access
  * 의미 : 레코드간 논리적 도는 물리적인 순서를 따라 차례대로 읽어 나가는 방식
    * 인덱스 리프 블록에 위치한 모든 레코드는 포인터를 따라 논리적으로 연결되어 있어서, 이 포인터를 따라 스캔하는 방식도 Sequential Access
    * 테이블 레코드 간에는 포인터로 연결되어 있지는 않지만 테이블 스캔할 때는 물리적으로 저장된 순서대로 읽어 나가므로 해달 방식도 Sequential Access
  * 성능 향상 방법
    * Multiblock I/O, 인덱스 Prefetch
* Random Access
  * 의미 : 레코드간 논리적, 물리적 순서를 따르지 않고, 한 건을 읽기 위해 한 블록씩 접근하는 방식
    * 주로 (4), (6)에서 성능 저하 발생
    * 하지만, NL조인의 Inner Table 액세스를 위한 (1), (2), (3)에서도 성능 저하 영향 발생 가능
  * 성능 향상 방법
    * 버퍼 Pinning, 테이블 Prefetch
* Sequential 액세스가 항상 Random Access보다 효율적인 것은 아니다
  * Seuqential 액세스의 경우, 선택도가 중요
    * 선택도 : 총 읽은 레코드에서 결과 집합으로 선택되는 비중
    * ex) Sequential Access로 100개를 읽었어도 그 중 99개를 버리고 1개의 결과 집합만 취한다면 Random Access보다 나을 것이 없다
* I/O 튜닝의 핵심 원리
  * Sequential 액세스의 선택도 (Selectivity)를 높인다
  * Random 액세스 발생량을 줄인다
 
<br>

### Sequential 액세스 선택도 높이기
* 49,906건이 담긴 테이블 (t))
```sql
CREATE TABLE t 
AS
SELECT * FROM all_objects
ORDER BY dbms_random.value;
```
* 24,613건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (49%) => 나쁘지 않은 Table Full Scan 효율성)
  * 읽은 블록 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'; 
```
* 1건의 결과집합 + 49,906건 TABLE ACCESS FULL T => 선택도 (0.002%) => 매우 낮은 Table Full Scan 효율성)
  * 읽은 블록 (CR) 691개
```sql
SELECT count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```
* 테이블 스캔 후 읽은 레코드들이 대부분 필터링되어 일부만 선택된다면 인덱스 사용이 더 효율적)
  * 1건의 결과집합 (INDEX RANGE SCAN T_IDX)
  * 읽은 블록 (CR) 76개
```sql
CREATE INDEX t_index ON t(owner, object_name);

SELECT  /*+ index(t t_idx) */ count(*) FROM t
WHERE   owner LIKE 'SYS%'
AND     object_name = 'ALL_OBJECTS';
```
* 인덱스로 읽은 레코드 개수 계산 예시)
  * 14,587건 Index Scan => 선택도 (0.007%) => Index Scan (Sequential Access)에서 비효율성 발생 가능
  * 인덱스 스캔도 충분히 비효율성이 발생 가능하다는 점을 인지해야함
    * 인덱스는 테이블과 달리 정렬된 순서를 유지하므로 일정 범위를 읽다가 멈출 수 있다는 점만 다르다
    * 다만, 인덱스 스캔의 효율은 조건절에 사용된 컬럼과 연산자 형태, 인덱스 구성에 의해 영향을 받는다
```sql
SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    ((owner = 'SYS' AND object_name >= 'ALL_OBJECTS') or (owner > 'SYS'));
```
* 인덱스 칼럼 순서를 변경한 예시)
  * from (owner, object_name) => to (object_name, owner)
  * 읽은 블록 (CR) 2개 
    * 인덱스 루트 블록 1개 + 리프 블록 1개
  * 1건의 결과집합 + 1건 INDEX RANGE SCAN T_IDX (정확히는 One-plus 스캔까지 2건) => 선택도 (100%) => 효율적인 Index Scan (Sequential Access) 발생
```sql
DROP INDEX t_idx;
CREATE INDEX t_index ON t(object_name, owner);

SELECT /*+ index(t t_idx) */ count(*) FROM t
WHERE  owner LIKE 'SYS%'
AND    object_name = 'ALL_OBJECTS';
```

<br>

### Random 액세스 발생량 줄이기
* 인덱스에 속하지 않는 칼럼 (object_id)을 참조하도록 쿼리를 변경함으로써 테이블 액세스 발생하는 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=739 ...)
    * 22934 | INDEX RANGE SCAN T_IDX (cr=51)
* 분석
  * 22,934 번만큼 테이블 방문 + 688 (739 - 51) 블록을 Random 액세스
  * 테이블을 22,934번만큼 방문하면서 내부적으로 22,934번 방문했지만 Random 액세스가 688번만 발생한 이유는 버퍼 Pinning 효과
    * 클러스터링 팩터 (인덱스 레코드가 가리키는 테이블 rowid 정렬 순서가 인덱스 키 값 정렬 순서와 일치하는 정도를 말한다)가 좋을수록 버퍼 Pinning에 의한 블록 I/O 감소 효과가 커진다
* 결과
  * 최종 한 건의 결과집합을 만들어 내기 위해서 너무나 많은 Random 액세스 (688)가 발생
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```
* 인덱스 단계에서 필터링할 수 있도록 인덱스에 (object_name)를 추가한 예시)
  * 1 | TABLE ACCESS BY INDEX ROWID T (cr=4 ...)
    * 1 | INDEX RANGE SCAN T_IDX (cr=3)
* 분석
  * 인덱스에서 1건 출력했기 때문에, 테이블을 1번 방문한다
  * 실제 발생한 Random 액세스도 1(4-3)건
* 결과
  * 동일한 SELECT문에 인덱스 구성 변경으로 테이블 Random 액세스 감소
```sql
DROP INDEX t_idx;

CREATE INDEX t_index ON t(owner, object_name);

SELECT object_id FROM t
WHERE  owner = 'SYS'
AND    object_name = 'ALL_OBJECTS';
```

<br>
<hr>
<br>

## Memory vs. Disk IO
#### 

<br>

### IO 효율화 튜닝의 중요성
* 모든 DBMS는 버퍼 캐시를 경유해 I/O를 수행한다.
  * 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고, 찾지 못할 때만 디스크에서 읽는 것
  * 버퍼 캐시는 유한한 메모리 자원을 효율적으로 사용하기 위해서 자주 액세스하는 블록들이 캐시에 더 오래 남아 있도록 LRU 알고리즘 사용

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/806f944f-891e-4449-bf02-000d6d389454">
</div>

* 물리적인 Disk I/O가 필요할 때는 서버 프로세스는 I/O 서브시스템에 I/O Call을 발생시키고 잠시 대기하게 되면서 비용이 커진다
  * 디스크에 발생하는 경합이 심할수록 대기 시간도 길어진다

<br>

### 버퍼 캐시 히트율 (Buffer Cache Hit Ratio - BCHR)
* BCHR 공식 - 물리적인 디스크 읽기를 수반하지 않고 곧바로 메모리에서 블록을 찾은 비율
  * (캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) * 100
  * ( (논리적 블록읽기 - 물리적 블록읽기) / 논리적 블록읽기) * 100
  * ( 1 - (물리적 블록읽기) ) / (논리적 블록읽기) ) * 100
* 용어
  * 논리적 블록읽기 = 총 읽은 블록 수
  * 캐시에서 곧바로 찾은 블록 수 = 논리적 블록읽기 - 물리적 블록읽기
* Direct Path Read 방식으로 읽는 경우를 제외하고, 모든 블록 읽기는 버퍼 캐시를 통해 이루어진다. 즉, 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾아보고 없을 때 디스크로부터 읽어들이며, 이때도 디스크로부터 곧바로 읽는 게 아니라 먼저 버퍼 캐시에 적재한 후에 읽는다
  * 무조건 버퍼 캐시에서 읽기 때문에 해당 방식으로 읽은 총 블록 수는 `논리적 블록읽기`
  * 따라서, 논리적 블록읽기 이후에 버퍼캐시에 원하는 블록이 없으면 물리적 물록읽기가 발생하기 때문에, 디스크를 동반하지 않은 버퍼캐시 읽기를 위하기 위해서는 `논리적 블록읽기 (Logical Reads)` - `물리적 블록읽기 (Physical Reads)`를 해줘야 한다
* SQL Trace 적용 예시)
  * 물리적 읽기 : Disk
  * 논리적 읽기 : Query + Current
  * BCHR (56%)
    * (1 - (Disk / ( Query + Current ))) * 100
    * (1 - (601,458 / (1,351,677 + 0))) * 100
    * 55.5%
  * 분석
    * 논리적으로 100개 블록 읽기 요청 => 56개는 메모리에서 바로 가져가기 + 44개는 디스크에서 가져오기
    * 다른 대기 이벤트가 없었다면 CPU Time과 Elapsed Time 간에 발생한 시간차는 대부분 디스크 I/O 때문
  * 결과
    * 논리적인 블록 요청 횟수를 줄이고, 물리적으로 디스크에서 읽어야할 블록 수를 줄이거는 것이 I/O 튜닝의 핵심 원리
    * BCHR의 결과 %는 높이고, 계산식에 사용하는 블록 I/O 값 자체도 낮은 값으로 유지하는 것이 좋다
      * 작은 테이블을 자주 액세스하면 모든 블록이 메모리에서 찾아져서 BCHR은 높지만 블록을 찾는 과정에서 래치를 얻어야 하므로 의외로 큰 비용을 수반한다
      * 특히, 같은 블록을 여러 세션이 동시에 액세스함으로 인해 래치 경합과 버퍼 Lock 경합까지 발생한다면 메모리 I/O 비용이 오히려 디스크 I/O 이상으로 커질 수 있다
      * 따라서, BCHR이 100%라고 하더라도 논리적으로 읽어야 할 블록 수의 절대량이 많다면 반드시 SQL 튜닝을 실시해서 논리적인 블록 읽기를 최소화해야 한다
      * 예) 대량의 데이터를 기준으로 NL 조인 방식을 사용해 작은 테이블을 반복적으로 Lookup 하는 경우가 대표적
 
<br>

### 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향

<br>
<hr>
<br>
