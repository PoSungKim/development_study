# 데이터베이스 Call 최소화 원리
> 불필요하고 반복적인 Call 수행횟수 최소화가 매우 중요
* 데이터베이스 Call = {Parse Call, Execute Call, Fetch Call}
* 데이터베이스 Call = {User Call, Recursive Call}

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/863a6853-2a63-4144-aa9c-3a23dcb2bf1b" >
</div>

<hr>
<br>

## Call 통계
#### 

<br>

### Call 통계
* Parse Call : 커서를 파싱하는 과정에 대한 통계 (실행계획을 생성하거나 찾는 과정)
  * 바인드 변수 사용
  * 세션 커서 캐싱
  * 애플리케이션 커서 캐싱 (Parse Call 아예 발생 X)
* Execute Call : 커서를 실행하는 단계에 대한 통계
  * INSERT, UPDATE, DELETE, MERGE 등 DML
  * INSERT ... SELECT
  * SELECT FOR UPDATE
* Fetch Call : SELECT문에서 실제 레코드를 읽어 사용자가 요구한 결과집합을 반환하는 과정에 대한 통계
  * SELECT
  * SORT
  * GROUP BY

<br>

### User Call vs Recursive Call
* User Call : OCI (Oracle Call Interface)를 통해 오라클 외부로부터 들어오는 Call
  * Peak 시간대의 시스템 장애 주범
  * 해결안
    * Loop 쿼리를 해소하고 집합적 사고를 통해 One-SQL로 구현
    * Array Processing : Array 단위 Fetch, Bulk Insert/Update/Delete
    * 부분범위처리 원리 활용
    * 효과적인 화면 페이지 처리 
    * 사용자 정의 함수/프로시저/트리거의 적절한 활용
* Recursive Call : 오라클 내부에서 발생하는 Call
  * 발생 요인 
    * SQL 파싱
    * 최적화 과정에서 발생하는 Data Dictionary 조회
    * PL/SQL로 작성된 사용자 정의 함수/프로시저/트리거 내에서의 SQL 수행
  * 해결안
    * 바인드 변수를 통한 하드파싱 발생횟수 감소
    * PL/SQL 내부 수행 이해 필요
  * Recursive Depth
    * 프로시저 내부에서 또 다른 프로시저 호출한 횟수
    * PL/SQL은 가상머신 (Virtual Machine) 상에서 수행되는 인터프리터(Interpreter) 언어이므로 빈번한 호출 시 컨텍스트 스위칭 (Context Switching)이 발생하여 성능 감소

| Call 구분 | User | Recursive |
|-----------|------|-----------|
| Parse     |Parse Call 최소화 --> 애플리케이션 커서 캐싱 기법|동일|
| Execute   |Array Processing, One-SQL로 구현, AP 설계 및 표준 가이드|Array Processing, 함수 반복 호출 최소화 (조인, 스칼라 서브쿼리 활용)|
| Fetch     |Array 단위 Fetch, 부분범위처리 활용, 페이지 처리|Cursor FOR Loop문 사용|

<br>
<hr>
<br>

## 데이터베이스 Call이 성능에 미치는 영향
#### 

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/cfff5131-6a90-44a8-91d5-5f7677739a15" >
</div>

<br>

### 데이터베이스 Call이 성능에 미치는 영향
* 월요금납부실적 테이블로 납입방법별_월요금집계 테이블을 집계하는 형태
  * 기간계 : 월요금납부실적
  * 정보계 : 납입방법별_월요금집계
* Bad) PL/SQL
  * PARSE CALL
  * EXECUTE CALL
* Bad) Java
  * PARSE CALL
  * PARSE CALL + EXECUTE CALL
  ```java
  class JavaLoopQuery {
    public static void insertData(Connection con
                                  , String param1
                                  , String param2
                                  , String param3
                                  , long param4) throws Exception {

        String SQLStmt = "INSERT INTO 납입방법별_월요금집계 "
                       + "(고객번호, 납입월, 납입방법코드, 납입금액) "
                       + "VALUES(?, ?, ?, ?, ?)"
                ;

        PreparedStatement st = con.prepareStatement(SQLStmt);
        st.setString(1, param1);
        st.setString(2, param2);
        st.setString(3, param3);
        st.setLong(4, param4);
        st.execute();
        st.close();
    }

    public static void execute(Connection con, String input_month) throws Exception {
        String SQLStmt = "SELECT 고객번호, 납입월"
                       + ", 지로, 자동이체, 신용카드, 핸드폰, 인터넷 "
                       + "FROM 월요금납부실적 "
                       + "WHERE 납입월 = ?"
                ;

        PreparedStatement stmt = con.prepareStatement(SQLStmt);
        stmt.setString(1, input_month);

        ResultSet rs = stmt.executeQuery();

        while(rs.next()) {
            String 고객번호 = rs.getString(1);
            String 납입월  = rs.getString(2);
            long 지로     = rs.getLong(3);
            long 자동이체  = rs.getLong(4);
            long 신용카드  = rs.getLong(5);
            long 핸드폰   = rs.getLong(6);
            long 인터넷   = rs.getLong(7);

            if (지로    > 0) insertData(con, 고객번호, 납입월, "A", 지로);
            if (자동이체 > 0) insertData(con, 고객번호, 납입월, "B", 자동이체);
            if (신용카드 > 0) insertData(con, 고객번호, 납입월, "C", 신용카드);
            if (핸드폰  > 0) insertData(con, 고객번호, 납입월, "D", 핸드폰);
            if (인터넷  > 0) insertData(con, 고객번호, 납입월, "E", 인터넷);
        }

        rs.close();
        stmt.close();
    }

    public static void main(String[] args) throws Exception {
        Connection con = getConnection();
        execute(con, "200903");
        releaseConnection(con);
    }
  }
  ```
* 특히 Java 성능이 낮음
  * User Call이 Recursive Call에 비해서 더 심각한 부하를 일으키는 이유
    * 네트워크 구간에서 소비한 시간
    * 데이터베이스 Call이 발생할 때마다 매번 OS로부터 CPU와 메모리 리소스를 할당받으려고 소비한 시간
  * 순수하게 서버에서 처리한 시간은 미미
* Better) One-SQL (INSERT INTO ... SELECT)
  * 데이터베이스 Call 횟수를 줄이는 데에 있음
    * Sort Merge Join 또는 Hash Join으로 유도하기 위한 튜닝 가능
  ```sql
  INSERT INTO 납입방법별_월요급집계(납입월, 고객번호, 납입방법코드, 납입금액)
  SELECT /*+ USE_MERGE(X Y) NO_EXPAND NO_MERGE (X) */ x.납입월, x.고객번호
        , CHR(64 + Y.NO) 납입방법코드
        , DECODE(Y.NO, 1, 지로, 2, 자동이체, 3, 신용카드, 4, 핸드폰, 5, 인터넷)
  FROM   월요금납부실적 x
        , (SELECT LEVEL NO FROM DUAL CONNECT BY LEVEL <= 5) y
  WHERE  x.납입월 = "200903"
  AND    y.NO IN (
          DECODE(지로, 0, NULL, 1)
        , DECODE(자동이체, 0, NULL, 2)
        , DECODE(신용카드, 0, NULL, 3)
        , DECODE(핸드폰, 0, NULL, 4)
        , DECODE(인터넷, 0, NULL, 5)
        )
  ```
* Good) Java Array Processing
  * 네트워크 구간에서 소비한 시간을 줄일 수 있다
* `납입방법별_월요금집계` 테이블로 `월요금납부실적` 만들기
```sql
INSERT INTO 월요금납부실적
(고객번호, 납일월, 지로, 자동이체, 신용카드, 핸드폰, 인터넷)
SELECT K.고객번호, '200903' 납입월
      , A.납입금액 지로
      , B.납입금액 자동이체
      , C.납입금액 신용카드
      , D.납입금액 핸드폰
      , E.납입금액 인터넷
FROM  고객 K
      , (SELECT 고객번호, 납입금액 FROM 납입방법별_월요금집계
         WHERE  납입월 = '200903'
         AND    납입방법코드 = 'A') A
      , (SELECT 고객번호, 납입금액 FROM 납입방법별_월요금집계
         WHERE  납입월 = '200903'
         AND    납입방법코드 = 'B') B
      , (SELECT 고객번호, 납입금액 FROM 납입방법별_월요금집계
         WHERE  납입월 = '200903'
         AND    납입방법코드 = 'C') C
      , (SELECT 고객번호, 납입금액 FROM 납입방법별_월요금집계
         WHERE  납입월 = '200903'
         AND    납입방법코드 = 'D') D
      , (SELECT 고객번호, 납입금액 FROM 납입방법별_월요금집계
         WHERE  납입월 = '200903'
         AND    납입방법코드 = 'E') E
WHERE  A.고객번호(+) = K.고객번호
AND    B.고객번호(+) = K.고객번호
AND    C.고객번호(+) = K.고객번호
AND    D.고객번호(+) = K.고객번호
AND    E.고객번호(+) = K.고객번호
```
```sql
INSERT INTO 월요금납부실적 (고객번호, 납입월, 지로, 자동이체, 신용카드, 핸드폰, 인터넷)
SELECT 고객번호, 납입월
      , NVL(SUM(DECODE(납입방법코드, 'A', 납입금액)), 0) 지로
      , NVL(SUM(DECODE(납입방법코드, 'B', 납입금액)), 0) 자동이체
      , NVL(SUM(DECODE(납입방법코드, 'C', 납입금액)), 0) 신용카드
      , NVL(SUM(DECODE(납입방법코드, 'D', 납입금액)), 0) 지로
      , NVL(SUM(DECODE(납입방법코드, 'E', 납입금액)), 0) 인터넷
FROM   납입방법별_월요금집계
WHERE  납입월 = '200903'
GROUP BY 고객번호, 납입월;
```
* 쇼핑몰 WishList 예시
  * 5 * Parse Call + 5 * Execute Call
    ```java
    void insertWishList( String p_custid, String p_goods_no ) throws SQLException {
        String SQLStmt = "insert into wishlist "
                        + "select custid, goods_no "
                        + "from cart "
                        + "where custid = ?"
                        + "and goods_no = ?";
        
        PreparedStatement stmt = con.preparedStatement(SQLStmt);
        stmt.setString(1, p_custid);
        stmt.setString(2, p_goods_no);
        stmt.execute();
    }
    ```
  * 1 * Parse Call + 1 * Execute Call
    ```java
    void insertWishList2( String p_custid, String[] p_goods_no ) throws SQLException {
        String SQLStmt = "insert into wishlist "
                        + "select custid, goods_no "
                        + "from cart "
                        + "where custid = ?"
                        + "and goods_no in (?, ?, ?, ?, ?)";
    
        PreparedStatement stmt = con.preparedStatement(SQLStmt);
        stmt.setString(1, p_custid);
        for(int i = 0; i < 5; i++) {
            stmt.setString(i + 2, p_goods_no[i]);
        }
        stmt.execute();
    }
    ```

<br>
<hr>
<br>

## Array Processing 활용
#### 한 번의 SQL 수행으로 다량의 로우를 동시에 insert/update/delete 가능

<br>

### Array Processing 활용
* 네트워크를 통한 데이터베이스 Call을 감소시켜주고, SQL 수행시간 및 CPU 사용량 또한 감소

```java
class JavaArrayProcessing {
    public static void insertData( Connection con,
                                   PreparedStatement st,
                                   String param1,
                                   String param2,
                                   String param3,
                                   long param4) throws Exception {
        st.setString(1, param1);
        st.setString(2, param2);
        st.setString(3, param3);
        st.setLong(4, param4);
        st.addBatch();
    }

    public static void execute(Connection con, String input_month) throws Exception {
        long rows = 0;
        String SQLStmt1 = "SELECT 고객번호, 납입월"
                            + ", 지로, 자동이체, 신용카드, 핸드폰, 인터넷 "
                            + "FROM 월요금납부실적 "
                            + "WHERE 납입월 = ?";

        String SQLStmt2 = "INSERT INTO 납입방법별_월요금집계 "
                            + "(고객번호, 납입월, 납입방법코드, 납입금액) "
                            + "VALUES(?, ?, ?, ?)";

        con.setAutoCommit(false);

        PreparedStatement stmt1 = con.prepareStatement(SQLStmt1);
        PreparedStatement stmt2 = con.prepareStatement(SQLStmt2);

        stmt1.setFetchSize(1000);
        stmt1.setString(1, input_month);

        ResultSet rs = stmt1.executeQuery();

        while(rs.next()) {
            String 고객번호 = rs.getString(1);
            String 납입월 = rs.getString(2);
            long 지로 = rs.getLong(3);
            long 자동이체 = rs.getLong(4);
            long 신용카드 = rs.getLong(5);
            long 핸드폰 = rs.getLong(6);
            long 인터넷 = rs.getLong(7);

            if (지로 > 0)
                insertData(con, stmt2, 고객번호, 납입월, "A", 지로);

            if (자동이체 > 0)
                insertData(con, stmt2, 고객번호, 납입월, "B", 자동이체);

            if (신용카드 > 0)
                insertData(con, stmt2, 고객번호, 납입월, "C", 신용카드);

            if (핸드폰 > 0)
                insertData(con, stmt2, 고객번호, 납입월, "D", 핸드폰);

            if (인터넷 > 0)
                insertData(con, stmt2, 고객번호, 납입월, "E", 인터넷);

            if (++rows % 1000 == 0) stmt2.executeBatch();
        }

        rs.close();
        stmt1.close();

        stmt2.executeBatch();
        stmt2.close();

        con.commit();
        con.setAutoCommit(true);
    }
}
```
* Array Processing
  * addBatch()
  * executeBatch()
  * setFetchSize(int rows)

|              | PL/SQL (Recursive) | JAVA     | JAVA (Array 처리) | One-SQL |
|--------------|--------------------|----------|-------------------|---------|
| Parse Call   | 5                  | 150,000  | 1                 | 1       |
| Execute Call | 150,000            | 150,000  | 30                | 1       |
| 총 소요시간  | 7.26초             | 126.82초 | 1.21초            | 0.9초   |

<br>
<hr>
<br>

## Fetch Call 최소화
#### 

<br>

### 부분범위처리 원리
* Java 예시)
  * 1억 건이 담긴 big_table이지만, 곧바로 결과가 리턴된 케이스
  * while문이 아니고, if문이라는 점이 키 포인트
```java
private void execute(Connection con) throws Exception {
    Statement stmt = con.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT name FROM big_table");

    if (rs.next()) {
        System.out.println(rs.getString(1));
    }

    rs.close();
    stmt.close();
}
```
* SQL 예시)
  * ArraySize가 5로 세팅
  * 결과집합인 (1,1), (2,2), (3,3), (4,4), (5,5)까지 곧바로 리턴
  * 마지막 결과집합인 (6,6)은 33초가 경과한 후에 이 라인을 출력하고 수행 종료
```sql
CREATE TABLE t (
  x NUMBER not null
, y NUMBER not null);

INSERT INTO t
SELECT *
FROM  (
  SELECT rownum x, rownum y
  FROM   dual
  CONNECT BY LEVEL <= 5000000
) ORDER BY dbms_random.value;

ALTER TABLE t
ADD CONSTRAINT t_pk PRIMARY KEY (x);

ALTER SYSTEM FLUSH BUFFER_CACHE;

SET arraysize 5
SET timing on

SELECT /*+ index(t t_pk) */ x, y
FROM   t
WHERE  x > 0
AND    y <= 6;
```
* DBMS는 데이터를 클라이언트에게 전송할 때 일정량씩 나누어 전송한다
  * 오라클
    * ArraySize (또는 FetchSize) 설정을 통해 운반단위를 조절한다
    * 전체 결과집합 중 아직 전송하지 않은 분량이 ㅁ낳이 남아있어도 클라이언트로부터 추가 Fetch Call을 받기 전까지는 그대로 멈춰 서서 기다린다
* Java 예시에 적용
  * if문이었기 때문에 rs.next()가 한 번만 호출하고 ResultSet와 Statement를 close했다
    * 즉, rs.next()를 호출하는 순간, 오라클은 FetchSize (Java Default : 10)만큼을 전송한 이후에 클라이언트는 그 중 한 건만 콘솔에 출력하고 바로 커서를 close한 케이스
  * 오라클은 1억건을 모두 전송한 것이 아니라 세팅대로 10건만 전송했고, 자바에서는 10건 중 1건만 콘솔에 출력하고 커서를 닫았기 때문에 곧바로 종료되는 것이다
* SQL 예시에 적용
  * ArraySize가 5이기 때문에, 5건이 먼저 전송된 이후, 마지막에 남은 1건이 전송되었다
    * 단위가 5이기 때문에, 5건 + 1건이 독립적으로 전송된 것이다
* 쿼리 결과집합을 전송할 때, 전체 데이터를 쉼 없이 연속적으로 처리하지 않고 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어서 전송하는 것이 `부분범위처리`
* SDU, TDU
  * ArrayFetch 수행 내부 매커니즘
    * ArraySize를 5로 설정하면, 서버 측에서는 Oracle Net으로 데이터를 내려 보내다가 5건당 한 번씩 전송 명령을 날리고는 클라이언트로부터 다시 Fetch Call이 올 때까지 대기한다
    * 클라이언트 측에는 서버로부터 전송닫은 5개 레코드를 담을 Array 버퍼가 할당되며, 그곳에 서버로부터 받은 데이터를 담았다가 한 건씩 화면에 출력하거나 다른 작업들을 수행한다
  * 데이터 버퍼
    * 클라이언트 : Array에 버퍼링
    * 서버 : SDU에 버퍼링
  * OSI 7 레이어
    * Application, Presentation, Session, Transport, Network, Data Link, Physical
  * SDU (Session Data Unit)는 Session 레이어 데이터 버퍼에 대한 규격
    * 네트워크를 통해 전송하기 전에 Oracle Net이 데이터를 담아 두려고 사용하는 버퍼
  * TDU (Transport Data Unit)는 Transport 레이어 데이터 버퍼에 대한 규격
    * 물리적인 하부 레이어로 내려보내기 전에 데이터를 잘게 쪼개어 클라이언트에게 전송되는 도중에 유실이나 에러가 없도록 제어하는 역할
  * TNSNAMES.ORA, LISTENER.ORA
    * (SDU=2048)(TDU=1024) : SDU 및 TDU 사이즈 설정 가능
    * 예) 결과집합 (18건), 로우당 900B, ArraySize 5
      * Fetch 총 4번
        * 5건 (4,500B)
        * 5건 (4,500B)
        * 5건 (4,500B)
        * 3건 (2,700B)
      * SDU 총 11패킷
        * 3패킷 (4,500B)
          * 2,048 + 2,048 + 404
        * 3패킷 (4,500B)
          * 2,048 + 2,048 + 404
        * 3패킷 (4,500B)
          * 2,048 + 2,048 + 404
        * 3패킷 (2,700B)
          * 2,048 + 652
      * TDU 총 18패킷
        * 5패킷 (4,500B)
          * (1,024 + 1,024) + (1,024 + 1,024) + 1,024 + 404
        * 5패킷 (4,500B)
          * (1,024 + 1,024) + (1,024 + 1,024) + 1,024 + 404
        * 5패킷 (4,500B)
          * (1,024 + 1,024) + (1,024 + 1,024) + 1,024 + 404
        * 3패킷 (2,700B)
          * (1,024 + 1,024) + 652
      * 즉, Fetch Call에 대한 실제 Fetch 데이터 전송은 내부적으로 4번 발생하되, 각 Fetch 데이터 전송에서도 내부적으로 레이어가 내려가면서 데이터 바이트 크기가 SDU 및 TDU 단위로 쪼개져서 전송된다

<br>

### OLTP 환경에서 부분범위처리에 의한 성능개선 원리

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/9e572c60-479f-4610-b970-6270bfc5c9aa">
</div>

* Fetch Call 2번
  * 첫 번째 : 5건이 바로 ArraySize (setting : 5)를 모두 채우면서 지체없이 리턴
    * 오라클 서버는 5개를 바로 찾아서 바로 클라이언트에게 전송
    * 클라이언트는 Array버퍼에 담긴 5건 레코드 바로 출력
  * 두 번째 : 1건이 결과적으로 ArraySize (setting : 5)를 채워서 시간소요와 함께 리턴
    * 첫 번째 Fetch Call처럼 5건을 모두 채우는 케이스가 아님
    * 오라클 서버는 WHERE 조건문을 만족하는 레코드가 더 이상 없다는 것을 모르기 때문에 끝까지 인덱스를 액세스하면서 테이블을 액세스 한다
    * 결국, 끝까지 도달한 이후에야 더는 전송할 데이터가 없음을 인식하고 그대로 한 건만 전송하도록 Oracle Net에 명령을 보낸다
    * Oracle Net은 한 건만 담은 패킷을 클라이언트에게 전송한다
    * 클라이언트 입장에서는 Array 버퍼가 다시 채워지기를 기다리면서 30여 초 이상을 허비했지만 결국 한 건밖에 없다는 신호를 받고 이를 출력한 후에 커서를 닫는다
* 이런 부분범위 처리 원리 때문에 OLTP 환경에서는 결과집합이 많을수록 오히려 성능이 더 좋아진다

```sql
--SQL1
SELECT /*+ index(t t_pk) */ x, y FROM   t  WHERE  x > 0  AND    mod(y) <= 500;
--SQL2
SELECT /*+ index(t t_pk) */ x, y FROM   t  WHERE  x > 0  AND    mod(y) <= 50000;
```

* 클라이언트 Array 버퍼 테스팅
  * ArraySize : 10
  * SQL1 : 매칭되는 레코드를 바로 바로 Oracle Net에 전송 (500번째 매칭건이 스캔될 때마다 Oracle Net에 전송될 레코드와 전송 명령을 전달)
  * SQL2 : 매칭되는 레코드를 바로 바로 Oracle Net에 전송 (50000번째 매칭건이 스캔될 때마다 Oracle Net에 전송될 레코드와 전송 명령을 전달)
  * 테스트의 포인트 : 클라이언트 Array 버퍼가 채워지는 속도 차이에 따라 화면 출력 속도도 달라짐을 확인할 수 있다
* OLTP성 업무에서는 쿼리 결과 집합의 일부만 Fetch하고 멈추는 경우가 많다
  * 빠르게 채워서 필요한만큼만의 건수들을 Client에 전달할 수 있는 ArraySize를 찾는 것이 중요
  * 인덱스 및 부분범위처리 원리에 대한 이해력이 중요
* 물론, 서버 가공 프로그램이나 DW성 쿼리처럼 결과 집합의 일부가 아닌 전체를 Fetch해야 하는 케이스에서 결과 집합이 커질 수록 더 느릴 수밖에 없다
* One-Row Fetch
  * Orange, SQL*Plus는 항상 첫 Fetch Call에서는 한 건만 요청 (One-Row Fetch)
  * 클라이언트 툴마다 Fetch하는 방식은 상이할 수 있지만, 오라클 서버에서는 항상 Array 단위로 전송한다는 점은 동일
  
<br>

### ArraySize 조정에 의한 Fetch Call 감소 및 블록 I/O 감소 효과
* 대량 데이터를 조회하는 상황에서 ArraySize가 커지면
  * Fetch Call 횟수 감소
  * 네트워크 부하 감소
  * 쿼리 성능 상승
  * 서버 프로세스에서 읽는 블록 개수 감소
 
```sql
CREATE TABLE test AS SELECT * FROM all_objects;

SET AUTOTRACE traceonly STATISTICS;

SET arraysize 2;

SELECT * FROM test;
```

* AutoTrace
  * db block gets
  * consistent gets
  * physical reads
  * SQL*Net roundtrips to/crom client
  * rows processed
* SQL Trace
  * current
  * query
  * disk
  * count
  * rows
* ArraySize와 {Fetch Count (SQL*Net roundtrips), DB I/O}는 반비례 관계 및 내부 원리

<div align="center">
  <img width="50%" src="https://github.com/PoSungKim/development_study/assets/37537227/544d2a8f-f92d-4219-8fc4-6f7afaa77332">
</div>

<br>

### 프로그램 언어에서 Array 단위 Fetch 기능 활용
* SQL*Plus이 아닌, PL/SQL을 포함한 프로그래밍 언어 기반 ArraySize 제어 방법
* 일반 PL/SQL FOR Loop 예시)
  * Array Processing (1000) 기능 자동 세팅
  * FOR Loop 유형
    * Implicit Cursor FOR Loop
    * Explicit Cursor FOR Loop
```plsql
for item in cursor
loop
  ....
end loop;
```
```sql
--Implicit Cursor FOR Loop
declare
    l_object_name big_table.object_name%type;
begin
    for item in (select object_name from big_table where rownum <= 1000)
    loop
        l_object_name := item.object_name;
        dbms_output.put_line(l_object_name);
    end loop;
end;

--Explicit Cursor FOR Loop
declare
    l_object_name big_table.object_name%type;
    cursor c is select object_name from big_table where rownum <= 1000; 
begin
    for item in c
    loop
        l_object_name := item.object_name;
        dbms_output.put_line(l_object_name);
    end loop;
end;
```

```sql
SELECT OBJECT_NAME
FROM   BIG_TABLE
WHERE  ROWNUM <= 1000
```
* 일반 Cursor 예시)
  * Array 단위 Fetch가 작동하지 않는다
* 일반 Java 예시)
  * Java의 default FetchSize는 10
  * `.setFetchSize()` 로 조정가능
  * 예시 내부 매커니즘
    * 최초 rs.next() 호출로 100건 가져와서 클라이언트 Array 버퍼에 캐싱
    * 이후 rs.next() 호출로 100건으로 찬 Array 버퍼에서 Read
    * 101번째 같이 내부 Array 버퍼를 모두 읽은 이후의 최초 rs.next()는 최초 rs.next()부터 동일하게 동작하면서 모든 결과집합을 다 읽을 때까지 반복
```java
public static void selectWithFetchSizeSetup(Connection con) throws SQLException {
    String sql = "select custid, name from customer";
    PreparedStatement stmt = con.prepareStatement(sql);
    stmt.setFetchSize(100); // PreparedStatement에서 조정 가능

    ResultSet rs = stmt.executeQuery();
    //rs.setFetchSize(100); // ResultSet에서도 조정 가능

    while( rs.next() ) {
        int empno = rs.getInt(1);
        String ename = rs.getString(2);
        System.out.println(empno + ":" + ename);
    }

    rs.close();
    stmt.close();
}
```

<br>

### 페이지 처리의 중요성
* 안 좋은 예시)
  * Page가 뒤로 갈 수록 Fetch Call이 누적되면서 증가
  * FetchSize를 늘리더라도, Fetch Call Count는 감소하겠지만, 리소스 과부하는 여전
```java
public static void pagination(ResultSet rs, long pageNo, int pageSize) throws SQLException {
    int i = 0;
    while ( rs.next() ) {
        if (++i > (pageNo - 1) * pageSize) printRow(rs);
        if ( i == pageNo *pageSize) break;
    }
}
```
```sql
i := 0;
loop
    fetch c into l_record;
    exit when (c%notfound or (i = pageNo * pageSixze))
    i := i + 1;
    if i > (pageNo - 1) * pageSize then
        printRow(l_record);
    endif;
end loop;
```
* 해결책 (페이지 처리)
  * 페이지 처리를 서버 단에서 완료하고 최종적으로 출력할 레코드만 Fetch하도록 프로그램 수정
* 페이지 처리를 하지 않음으로부터 발생하는 부작용
  * 다량의 Fetch Call 발생 (SQL*Net roundtrips to/from client)
  * 대량의 결과 집합을 클라이언트로 전송하면서 발생하는 네트워크 부하 (bytes sent via SQL*Net to client)
  * 대량의 데이터 블록을 읽으면서 발생하는 I/O 부하
  * AP 서버 및 웹 서버 리소스 사용량 증가
* 페이지 처리를 함으로부터 발생하는 이점
  * 페이지 단위로, 화면에서 필요한 만큼씩 Fetch Call
  * 페이지 단위로, 화면에서 필요한 만큼씩 네트워크를 통해 전송
  * 인덱스와 부분범위처리 원리를 이용해 각 페이지에 필요한 최소량만 I/O
  * 데이터를 소량씩 나누어 전송하므로 AP, 웹 서버 리소스 사용량 최소화

<br>
<hr>
<br>

## PL/SQL 함수의 특징과 성능 부하
#### 

<br>

### PL/SQL 함수의 특징
* PL/SQL로 작성하 함수/프로시저를 컴파일하면, Java처럼 ByteCode가 되고, 이를 실행하는 PL/SQL 엔진 (Virtual Machine) 위에서 동작한다
* ByteCode는 데이터 딕셔너리에 저장되었다가 런타임 시 해석된다
* PL/SQL은 인터프리터 언어이므로 그것으로 작성한 함수 실행 시 매번 SQL 실행엔진과 PL/SQL 가상머신(Virtual Machine) 사이에 컨텍스트 스위칭 (Context Switching) 발생
* 함수/프로시저 성능이 나빠지는 이유는 내부에서 Recursive SQL을 수행하기 때문
  * Recursive Call도 Execute Call과 Fetch Call 발생시킨다

<br>

### Recursive Call을 포함하지 않는 함수의 성능 부하
* 성능 감소

<br>

### Recurisve Call을 포함하는 함수의 성능 부하
* Recursive Call을 포함하지 않는 함수보다 더 성능 감소
* 대용량 조회 쿼리 SELECT문에서 함수를 남용하면 읽는 레코드 수만큼 건건이 함수 호출 발생
  * 사용을 제한하거나 조인 혹은 스칼라 서브쿼리 형태로 변환 필요
 
<br>

### 함수를 필터 조건으로 사용할 때 주의 사항
* 함수를 WHERE절에서 필터 조건으로 사용할 때도 주의 필요
```sql
create or replace function emp_avg_sal return number
is
    l_avg_sal number;
begin
    select avg(sal) into l_avg_sal from emp;
    return l_avg_sal;
end;

create index EMP_X01 on emp(sal);
create index EMP_X01 on emp(deptno);
create index EMP_X01 on emp(deptno, sal);
create index EMP_X01 on emp(deptno, ename, sal);
```

* 케이스 1) full(emp)
  * 테이블 전체 건수만큼 함수 호출
    * emp 테이블 14건만큼 14 * Execute Call + 14 * Fetch Call 발생
  * 총건수 (14)
```sql
SELECT /*+ full(emp) */ * from emp
where sal >= avg_sal
```

* 케이스 2) index(emp (sal))
  * 인덱스 액세스 횟수인 1번 호출
    * 함수를 먼저 실행하고, EMP_X01 인덱스를 액세스하는 상수 조건으로 사용
  * Predicate Information의 access 조건
    * `access("SAL">="EMP_AVG_SAL"())`
```sql
SELECT /*+ index(emp (sal)) */ * from emp
where sal >= avg_sal
```

* 케이스 3) index(emp, EMP_X02)
  * 테이블 액세스 횟수만큼 함수 호출 발생
  * Predicate Information의 filter 조건
    * deptno는 인덱스 액세스 조건 + sal은 테이블 필터 조건
      * `access("DEPTNO"=20)`
      * `filter("SAL">="EMP_AVG_SAL"())`
  * 총건수 (14) --> 인덱스 액세스 (5) --> 필터링 조건 (3)
```sql
SELECT /*+ index(emp, EMP_X02) */ * from emp
where sal >= avg_sal
and   deptno = 20
```

* 케이스 4) index(emp (deptno, sal))
  * 인덱스 액세스 횟수인 1번 호출
  * Predicate Information의 access 조건
    * (deptno, sal)은 인덱스 액세스 조건
      * `access("DEPTNO"=20 AND "SAL">="EMP_AVG_SAL"() AND "SAL" IS NOT NULL)`
  * 총건수 (14) --> 인덱스 액세스 (3) 
```sql
SELECT /*+ index(emp (deptno, sal)) */ * from emp
where sal >= avg_sal
and   deptno = 20
```

* 케이스 5) index(emp (deptno, ename, sal))
  * ename 조건이 없어서 인덱스 액세스 및 테이블 엑세스 횟수 그리고 one-plus 스캔 1회를 모두 더한만큼 호출
  * 인덱스 칼럼 구성상 선행 칼럼이 누락되는 경우, 필터 조건으로 사용
  * Predicate Information의 access + filter 조건
    * (deptno, sal)은 인덱스 액세스 조건 + (sal)은 인덱스 필터 조건
      * `access("DEPTNO"=20 AND "SAL">="EMP_AVG_SAL"())`
      * `filter("SAL">="EMP_AVG_SAL"())`
```sql
SELECT /*+ index(emp (deptno, ename, sal)) */ * from emp
where sal >= avg_sal
and   deptno = 20
```

* 케이스 6) index(emp (deptno, sal))
  * 인덱스 칼럼 구성상 '=' 조건이 아닌 경우, 필터 조건으로 사용
  * Predicate Information의 access + filter 조건
    * (deptno, sal)은 인덱스 액세스 조건 + (sal)은 인덱스 필터 조건
      * `access("DEPTNO"=20 AND "SAL">="EMP_AVG_SAL"() AND "SAL" IS NOT NULL)`
      * `filter("SAL">="EMP_AVG_SAL"())`
```sql
SELECT /*+ index(emp (deptno, sal)) */ * from emp
where sal >= avg_sal
and   deptno >= 10
```

| 조건절                          | 사용 인덱스                  | 함수 호출 횟수 |
|---------------------------------|------------------------------|----------------|
| sal >= emp_avg_sal              | Full Table Scan              | 14             |
| sal >= emp_avg_sal              | emp_x01 : sal                | 1              |
| sal >= emp_avg_sal deptno = 20  | emp_x02 : deptno             | 5              |
| sal >= emp_avg_sal deptno = 20  | emp_x03 : deptno, sal        | 1              |
| sal >= emp_avg_sal deptno = 20  | emp_x04 : deptno, ename, sal | 6              |
| sal >= emp_avg_sal deptno >= 10 | emp_x05 : deptno, sal        | 14             |


<br>

### 함수와 읽기 일관성
* 함수 내에서 수행되는 Recursive 쿼리는 메인 쿼리의 시작 시점과 무관하게 그 쿼리가 수행되는 시점을 기준으로 블록을 읽는다
  * 결국, 가장 기본적인 문장수준 읽기일관성 (Statement-level Consistency)가 보장되지 않는다
```sql
create table LookupTable ( key number, value varchar2(100) );

insert into LookupTable values ( 1, 'YAMAHA' );

commit;

create or replace function lookup(l_input number) return varchar2
as
    l_output LookupTable.value%TYPE;
begin
    select value into l_output from LookupTable where key = l_input;
    return l_output;
end;
```
* 일반 조인문 또는 스칼라 서브쿼리를 사용할 때만 완벽한 문장수준 읽기 일관성이 보장된다
```sql
-- 일반 조인문
select a.지수업종코드
      , min(a.지수업종명) 지수업종명
      , avg(c.현재가) 평균주식가격
      , sum(c.현재가 * c.발행주식수) 시가총액
from   지수업종 a, 지수업종구성종목 b, 종목별시세 c
where    a.지수업종유형코드 = '001'
and      b.지수업종코드 = a.지수업종코드
and      c.종목코드 = b.종목코드
group by a.지수업종코드;

-- 스칼라 서브쿼리
select a.지수업종코드
      , min(a.지수업종명) 지수업종명
      , avg(select 현재가 from 종목별시세
            where 종목코드 = b.종목코드) 평균주식가격
      , sum(select c.현재가 * c.발행주식수 from 종목별시세
            where 종목코드 = b.종목코드) 시가총액
from     지수업종 a, 지수업종구성종목 b
where    a.지수업종유형코드 = '001'
and      b.지수업종코드 = a.지수업종코드
group by a.지수업종코드
```
* 프로시저, 패키지, 트리거 등에서도 읽기 일관성이 깨지는 현상이 공통적으로 발생

<br>

### 함수의 올바른 사용 기준
* 

<br>
<hr>
<br>

## PL/SQL 함수 호출 부하 해소 방안
#### 

<br>

### 페이지 처리 또는 부분범위처리 활용
### Decode 함수 또는 Case문으로 변환
### 뷰 머지 (View Merge) 방지를 통한 함수 호출 최소화
### 스칼라 서브쿼리의 캐싱효과를 이용한 함수 호출 최소화
### Deterministic 함수의 캐싱 효과 활용
### 복잡한 함수 로직을 풀어 SQL로 구현

<br>
<hr>
<br>
