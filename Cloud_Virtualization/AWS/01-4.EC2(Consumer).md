# AWS EC2 (Consumer)
> Consumer 서버로 Spark 구동
* Standalone, 의사분산, 완전분산 모드 모두 가능
* 하단의 예시는 Standalone 모드

<hr>
<br>


## Spark 서버 구축 [:4040]
####

<br>

### [Spark Consumer 서버 : ]
```bash
wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz
tar xvzf spark-3.2.0-bin-hadoop3.2.tgz
ln -s spark-3.2.0-bin-hadoop3.2 spark

vi ~/.bash_profile
export SPARK_HOME=/home/ec2-user/spark

PATH=$PATH:$LS_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:
export PATH

spark-shell \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1

spark-submit \
  --class com.chatbot_spark.main \
  --master "local[*]" \
  --deploy-mode client \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0 \
  chatbot_spark-assembly-0.1.jar
```

<br>

### [Batch Read/Write && Streaming Read/Write]
```bash
val kd = spark.read.format("kafka").option("kafka.bootstrap.servers", "13.209.19.186:9092").option("subscribe", "chatbot").option("startingOffsets","earliest").load()
val response = kd.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
response.show
response.coalesce(1).write.mode("overwrite").csv("./test.csv")

val kd = spark.readStream.format("kafka").option("kafka.bootstrap.servers", "13.209.19.186:9092").option("subscribe", "chatbot").load()
val response = kd.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
val stream = response.writeStream.outputMode("append").format("console").start()

http://ec2-54-180-96-220.ap-northeast-2.compute.amazonaws.com:8081/runSparkBatch
```
* https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html#deploying

<br>
<hr>
<br>
