# AWS EC2
> 
*

<hr>
<br>

## 공통 사항
#### 접속 및 기본 설치

<br>

### [EC2 접속]
```bash
ssh -i ${pemDir} ${ec2Address}
```

<br>

### [Git 설치]
```bash
sudo yum install git -y
```

<br>
<hr>
<br>

## WEB 서버 구축 [:80]
#### Apache HTTP, Nginx 모두 가능

<br>

### [WEB 서버 설치 및 실행]
```bash
sudo yum install httpd -y
sudo service httpd start &

ps -ef | grep httpd
```

<br>

### [WEB 서버 HTML/CSS/JS 구축]
```bash
cd /var/www/html
scp -i ${pemDir} ${localDir} {ec2Dir}

sudo scp -r -i "Data_Engineering_Seoul.pem" /Users/posungkim/Desktop/Portfolio/git/chatbot_react/public/* ec2-user@ec2-13-124-198-75.ap-northeast-2.compute.amazonaws.com:/var/www/html

aws s3 cp s3://data-engineering-fintech/WEB/ /var/www/html/ --recursive
```

<br>
<hr>
<br>

## WAS 서버 구축 [:8080]
#### 

<br>

<br>
<hr>
<br>

## Kafka 서버 구축 [:9092], Kafka Producer 서버 구축, Kafka Consumer 서버 구축
####

<br>

### [Kafka 서버 : Java, Kafka 설치 후 Zookeeper 실행]

```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64

wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz
tar xvf kafka_2.13-3.0.0.tgz  
ln -s kafka_2.13-3.0.0 kafka // symbolic link

cd kafka
pwd

bin/zookeeper-server-start.sh config/zookeeper.properties &    // Zookeeper 실행
bin/kafka-server-start.sh config/server.properties &           // Kafka 실행 (9092)
sudo netstat -anp | egrep "9092|2181"                          // Kafka, Zookeeper 실행 유무 확인

bin/kafka-topics.sh --create --topic twitter --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092  & // twitter 토픽 추가
bin/kafka-topics.sh --list --bootstrap-server localhost:9092   // 현재 토픽 확인

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic twitter --from-beginning // Consumer 추가
```
* `config/server.properties` 파일 수정 필요!
  * https://minholee93.tistory.com/entry/ERROR-local-producer-cannot-connect-aws-ec2-kafka
* Spring
  * https://ckddn9496.tistory.com/68

<br>

### [Kafka Producer 서버 : Java, Kafka, Logstash 설치 ]

```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64

wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz
tar xvf kafka_2.13-3.0.0.tgz  
ln -s kafka_2.13-3.0.0 kafka // symbolic link

bin/kafka-console-producer.sh --topic twitter --bootstrap-server 172.31.40.67:9092 // 172.31.40.67 >> Kafka 내부 IP주소

wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
tar xvzf logstash-7.4.0.tar.gz
ln -s logstash-7.4.0 logstash

vi ~/.bash_profile
export LS_HOME=/home/ec2-user/logstash
PATH=$PATH:$LS_HOME/bin
source ~/.bash_profile
logstash --version

mkdir producer && cd producer
vi producer_test.conf

input {
  twitter {
    consumer_key => "KoxofBvIwdM9zz2JJ9vxg"
    consumer_secret => "kKBOnftLZ6htxvddgmZkzsii17ZeexCIgpIHNoWtE"
    oauth_token => "81761998-2Vu19ZxxFwEyik7XZ4ubG9mIj91wHdbIXdP08fId4"
    oauth_token_secret => "0E6eh4X0eum4NU81LXIKn6MMgH5TAWteL7asT8JxTo"
    keywords => ["news","game","bigdata","遺��숈궛"]
    full_tweet => true
  }
}

output{
  stdout{
    codec => rubydebug  
  }
}

logstash -f producer_test.conf 

cp producer_test.conf producer.conf
vi producer.conf

input {
  twitter {
    consumer_key => "KoxofBvIwdM9zz2JJ9vxg"
    consumer_secret => "kKBOnftLZ6htxvddgmZkzsii17ZeexCIgpIHNoWtE"
    oauth_token => "81761998-2Vu19ZxxFwEyik7XZ4ubG9mIj91wHdbIXdP08fId4"
    oauth_token_secret => "0E6eh4X0eum4NU81LXIKn6MMgH5TAWteL7asT8JxTo"
    keywords => ["news","game","bigdata","遺��숈궛"]
    full_tweet => true
  }
}

output{
  stdout{
    codec => rubydebug  
  }
  kafka {
          bootstrap_servers => "172.31.40.67:9092"
          codec => json{}
          acks => "1"
          topic_id => "twitter"
  }
}
```

<br>

### [Kafka Consumer 서버 :Java, Logstash 설치 ]
```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64

wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
tar xvzf logstash-7.4.0.tar.gz
ln -s logstash-7.4.0 logstash

vi ~/.bash_profile
export LS_HOME=/home/ec2-user/logstash
PATH=$PATH:$LS_HOME/bin
source ~/.bash_profile
logstash --version

mkdir consumer && cd consumer

vi consumer.conf

input {
        kafka {
                bootstrap_servers => "172.31.40.67:9092"
                topics => ["twitter"]
                consumer_threads => 1
                decorate_events => true
        }
}

output {
        stdout {
                codec=> rubydebug
        }
}

```

<br>
<hr>
<br>

## Spark 서버 구축 [:4040]
####

<br>

### []
```bash
spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1

val kd = spark.read.format("kafka").option("kafka.bootstrap.servers", "13.209.19.186:9092").option("subscribe", "chatbot").option("startingOffsets","earliest").load()
val response = kd.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
response.show
response.coalesce(1).write.mode("overwrite").csv("./test.csv")

val kd = spark.readStream.format("kafka").option("kafka.bootstrap.servers", "13.209.19.186:9092").option("subscribe", "chatbot").load()
val response = kd.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
val stream = response.writeStream.outputMode("append").format("console").start()



```
* https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html#deploying

<br>
<hr>
<br>
