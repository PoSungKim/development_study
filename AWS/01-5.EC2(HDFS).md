# HDFS (Distributed File System)
> 3가지의 모드 가능 (Standalone-독립모드, Pseudo-Distributed-의사분산모드, Fully-distributed-완전분산모드)
* 하나의 노드에서 프로세스별로 역할을 나누는 의사분산 모드로 결정 

<hr>
<br>

## HDFS 서버 구축 (의사분산 모드 - a single node)
#### [Hadoop Apache Official Guideline](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Installing_Software)

<br>

### [공통 설치]
```bash
sudo apt-get install ssh    // 클러스터 노드 간의 연결을 위한 설치      
sudo apt-get install pdsh   // 클러스터 노드 간에 동일한 .xml 설정 파일을 공유하기 위한 설치 >> 클라우데라 매니저와 같은 클러스터 관리 도구가 매우 유용!
```

<br>

### [HDFS 서버 : Java, Hadoop 설치]
```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64
vi ~/.bash_profile
JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.amzn2.0.2.x86_64
export PATH=$PATH:$JAVA_HOME/bin

cd ~
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
tar zxvf hadoop-3.3.1.tar.gz
ln -s hadoop-3.3.1 hadoop

vi ~/.bash_profile
export HADOOP_HOME=/home/ec2-user/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

<br>

### [SSH 설정]
```bash
sudo apt-get install ssh
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys

ssh localhost # 접속 가능 확인
```
* 의사분산 모드는 모든 호스트가 localhost인 특별한 케이스의 완전분산 모드
  * 하둡은 두 모드를 다르게 보지 못하며, 동일한 방식으로 실행시킨다
  * 따라서, 동일 셋업 필요

* ssh-keygen 옵션
  * -t : 알고리즘 선택
  * -P : old_passphrase (추가 비밀번호 세팅 >> ""은 안 쓴다는 의미)
  * -f : 저장할 파일명 지정. 경로 지정 가능

* `cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`
  * 의사분산 모드는 Client와 Host가 모두 Localhost에서 실행되기 때문에, ~ 홈 디렉토리의 .ssh/id_rsa.pub (Client 입장)를 .ssh/authorized_keys (Host 입장)에 넣어주는 것

<br>

### [속성 디렉토리 이동]
```bash
cd $HADOOP_HOME/etc/hadoop

vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh
JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.amzn2.0.2.x86_64
```

<br>

### [공통 속성 : core-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

<br>

### [HDFS 속성 : hdfs-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
```

<br>

### [MapReduce 속성 : mapred-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

<br>

### [Yarn 속성 : yarn-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuhffle</value>
  </property>
  <property>
      <name>yarn.nodemanager.env-whitelist</name>
      <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
  </property>
</configuration>
```

<br>

### [HDFS 파일시스템 포맷하기]
```bash
hdfs namenode -format

#datanode와 namenode의 clusterId가 안 맞을 때
hdfs namenode -format -clusterId CID-187b10ab-041d-4ad1-a966-fb10b4d945ac 
#혹은
sudo rm -rf /tmp/*
#혹은
namenode와 datanode의 clusterId를 맞춰주면 된다
```
* namenode가 메타 정보를 관리하기에 해당 정보를 포맷

<br>

### [데몬 시작]
```bash
useradd hdfs
useradd yarn

start-dfs.sh
start-yarn.sh
mapred --daemon start historyserver

jps                              # JVM에서 현재 실행되고 있는 데몬 리스트 확인 >> NameNode, SecondaryNameNode, DataNode, ResourceManager 확인 가능
hdfs getconf -namenodes          # localhost
hdfs getconf -secondaryNameNodes # 0.0.0.0
netstat -tvnp
```
* 기본 conf 디렉토리가 아닌, 별도의 conf 디렉토리 사용 시의 start-dfs.sh 
  * start-dfs.sh --config path-to-config-directory
  * export HADOOP_CONF_DIR=path-to-config-directory

* 실행 프로세스
  * HDFS : 네임노드, 보조 네임노드, 데이터노드
  * YARN : 리소스 매니저, 노드 매니저
  * MapReduce : 히스토리 서버

* 포트
  * http://localhost:9870       : 네임노드
  * http://localhost:9864       : 데이터노드
  * http://localhost:8088/conf  : 리소스 매니저
  * http://localhost:19888      : 히스토리 서버

<br>

### [Hadoop Log 디렉토리 설정]
```bash
vi ~/.bash_profile
export HADOOP_LOG_DIR=/var/log/hadoop
```

<br>

### [데몬 종료]
```bash
mapred --daemon stop historyserver
stop-yarn.sh
stop-dfs.sh
```

<br>
<hr>
<br>
