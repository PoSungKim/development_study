# HDFS
> 3가지의 모드 가능 ()
* 의사분산 모드로 결정 

<hr>
<br>

## HDFS 서버 구축 (의사분산 모드 - a single node)
#### [Hadoop Apache Official Guideline](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Installing_Software)

<br>

### [HDFS 서버 : Java, Hadoop 설치]
```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64

vi ~/.bash_profile

cd ~
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
tar zxvf hadoop-3.3.1.tar.gz
ln -s hadoop-3.3.1 hadoop

vi ~/.bash_profile
export HADOOP_HOME=/home/ec2-user/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

<br>

### [SSH 설정]
```bash
sudo apt-get install ssh
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

ssh localhost # 접속 가능 확인
```
* 의사분산 모드는 모든 호스트가 localhost인 특별한 케이스의 완전분산 모드
  * 하둡은 두 모드를 다르게 보지 못하며, 동일한 방식으로 실행시킨다
  * 따라서, 동일 셋업 필요

* ssh-keygen 옵션
  * -t : 알고리즘 선택
  * -P : old_passphrase (추가 비밀번호 세팅 >> ""은 안 쓴다는 의미)
  * -f : 저장할 파일명 지정. 경로 지정 가능

* `cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`
  * 의사분산 모드는 Client와 Host가 모두 Localhost에서 실행되기 때문에, ~ 홈 디렉토리의 .ssh/id_rsa.pub (Client 입장)를 .ssh/authorized_keys (Host 입장)에 넣어주는 것

<br>

### [공통 속성 : core-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost/</value>
  </property>
</configuration>
```

<br>

### [HDFS 속성 : hdfs-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
```

<br>

### [MapReduce 속성 : mapred-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

<br>

### [Yarn 속성 : yarn-site.xml]
```bash
<?xml version="1.0"?>
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuhffle</value>
  </property>
</configuration>
```

<br>

### [HDFS 파일시스템 포맷하기]
```bash
hdfs namenode -format
```
* namenode가 메타 정보를 관리하기에 해당 정보를 포맷

<br>

### [데몬 시작]
```bash
start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver

jps # JVM에서 현재 실행되고 있는 데몬 리스트 확인
```
* 기본 conf 디렉토리가 아닌, 별도의 conf 디렉토리 사용 시의 start-dfs.sh 
  * start-dfs.sh --config path-to-config-directory
  * export HADOOP_CONF_DIR=path-to-config-directory

* 실행 프로세스
  * HDFS : 네임노드, 보조 네임노드, 데이터노드
  * YARN : 리소스 매니저, 노드 매니저
  * MapReduce : 히스토리 서버

* 포트
  * http://localhost:50070 : 네임노드
  * http://localhost:8088  : 리소스 매니저
  * http://localhost:19888 : 히스토리 서버

<br>

### [데몬 종료]
```bash
mr-jobhistory-daemon.sh stop historysever
stop-yearn.sh
stop-dfs.sh
```

<br>
<hr>
<br>
