# Spark (2014)
> 인메모리 기반의 대용량 데이터 고속 처리 엔진으로 범용 분산 클러스터 컴퓨팅 프레임워크
* HDFS + MapReduce (Hadoop) 조합에서 MapReduce보다 100배 가량 더 나은 퍼포먼스를 보여주고 있다

<hr>
<br>

## 기본 개념
#### 

<br>

### Spark 탄생
* Hadoop MapReduce의 빈번한 `Disk I/O` 처리를 대체하기 위해서 `인메모리` 처리를 지원하는 Spark를 사용하기 시작
  * Spark: 최초 데이터 로드와 최종 결과 저장 시에만 디스크를 사용 
    * 메모리에 분산 저장 및 병렬처리

<br>

### 구성
* 컴포넌트
  * Spark Core
  * Spark Streaming : 실시간 데이터처리 기능 또한 장점
  * Spark SQL : Join 등 SQL related operations 모두 가능 
  * Spark MLlib
  * Spark GraphX
  * SparkR
* 특징
  * Cache in Memory
    * 연산의 결과를 Disk에 다시 적재하는 것이 아니라, Memory에 캐시로 저장함으로써 다음 연산으로 빠르게 이어질 수 있다는 특징이 Spark의 강점
  * OLTP보다는 OLAP용도로 적합
    * 현재까지는 작은 데이터면 굳이 Spark을 사용하지 않아도 되지만, 현대에는 데이터 크기가 지속적으로 크게 증가하는 추세이기 때문에, 미래에는 성능이 개선된 Spark가 OLTP로도 가능할 수도 있다는 내용도 있다
  * RDD (Resilient Distributed DataSets) - 분산 데이터 컬렉션
    * 컴퓨팅 클러스터로 분할 가능한 불변적 객체 컬렉션
  * HDFS, HBase, Cassandra, S3 등 다양한 Storage와 연동 가능
  * Cluster 유형
    * Standalone
    * YARN
    * Mesos 등 Cluster Manager와 연동 가능
  * Scala, Python, Java, R 등 다양한 언어 사용 가능
    * 성능 이슈로 인해, Scala(JVML) Python은 섞어서 사용한다고 함
    * 이러한 언어들로 Spark SQL을 실행
  * Spark Shell
    * Spark 클러스터의 대화형 콘솔로, scala로 바로 바로 실행 가능

<br>
<hr>
<br>

## 구조 
#### 

<br>

### 동작구조
* Driver
  * Spark Context
  * RDD
    * Transform and Action
    * Partition 
* Cluster Manager
* Worker Node
  * Executor
  * Task


<br>

### 프로그래밍 모델
* RDD >> Dataframe >> Dataset
