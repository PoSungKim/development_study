# Spark (2014)
> 인메모리 기반의 대용량 데이터 고속 처리 엔진으로 범용 분산 클러스터 컴퓨팅 프레임워크
* HDFS + MapReduce (Hadoop) 조합에서 MapReduce보다 100배 가량 더 나은 퍼포먼스를 보여주고 있다

<hr>
<br>

## 기본 개념
#### 

<br>

### Spark 탄생
* Hadoop MapReduce의 빈번한 `Disk I/O` 처리를 대체하기 위해서 `인메모리` 처리를 지원하는 Spark를 사용하기 시작
  * Spark: 최초 데이터 로드와 최종 결과 저장 시에만 디스크를 사용 
    * 메모리에 분산 저장 및 병렬처리

<br>

### 구성
* 컴포넌트
  * Spark Core
  * Spark Streaming : 실시간 데이터처리 기능 또한 장점
  * Spark SQL : Join 등 SQL related operations 모두 가능 
  * Spark MLlib
  * Spark GraphX
  * SparkR

* 특징
  * RDD (Resilient Distributed DataSets) - 분산 데이터 컬렉션
    * 컴퓨팅 클러스터로 분할 가능한 불변적 객체 컬렉션
    * 로컬 환경에서 사용되는 컬렉션으로 보이나, 실제로는 여러 노드에 분산된 데이터를 참조
    * 내부적으로, 병렬처리 프로그래밍으로 변환되어 실행된다
  * Cache in Memory
    * 연산의 결과를 Disk에 다시 적재하는 것이 아니라, Memory에 캐시로 저장함으로써 다음 연산으로 빠르게 이어질 수 있다는 특징이 Spark의 강점
    * RDD를 Cache로서 사용 `val oomLines = lines.filter(l => l.contains("OutOfMemoryError")).cache();
  * OLTP보다는 OLAP용도로 적합
    * 현재까지는 작은 데이터면 굳이 Spark을 사용하지 않아도 되지만, 현대에는 데이터 크기가 지속적으로 크게 증가하는 추세이기 때문에, 미래에는 성능이 개선된 Spark가 OLTP로도 가능할 수도 있다는 내용도 있다
  * HDFS, HBase, Cassandra, S3 등 다양한 Storage와 연동 가능
  * Cluster 유형
    * Standalone
    * YARN
    * Mesos 등 Cluster Manager와 연동 가능
  * Scala, Python, Java, R 등 다양한 언어 사용 가능
    * 성능 이슈로 인해, Scala(JVML) Python은 섞어서 사용한다고 함
    * 이러한 언어들로 Spark SQL을 실행
  * Spark Shell
    * Spark 클러스터의 대화형 콘솔로, scala로 바로 바로 실행 가능

<br>
<hr>
<br>

## 구조 
#### Spark API와 Runtime 아키텍처를 통해 분산 프로그래밍으로 실행된다
#### 다만, 이러한 분산 아키텍처로 인해 오버헤드가 있기에 OLTP보다는 OLAP에 더 적합

<br>

### 혁명
* 병렬 처리
* 데이터 분산
* 장애 내성

<br>

### 동작구조
* Driver
  * Spark Context
  * RDD (불변성,복원성,분산)
    * Transform and Action
    * Partition 
* Cluster Manager
* Worker Node
  * Executor
  * Task

<br>

### 프로그래밍 모델
* RDD >> Dataframe >> Dataset

<br>
<hr>
<br>

## Batch vs Streaming
#### Batch : 일괄 작업으로 Spark은 일괄처리를 지향함
#### Streaming : 실시간 작업 또한 Spark에서 가능한데, 일괄처리를 지향하는 Spark은 Mini-Batch 개념 (일정 시간 내에 유입된 데이터 블록으로 RDD 구성)을 통해 Streaming 데이터 처리 방식을 처리

<br>

### SparkContext

```scala

```

<br>

### StreamingContext

```scala

```
