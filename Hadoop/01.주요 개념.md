# 주요 개념 
> Hadoop: The Definitive Guide
* [Official Site](http://www.hadoopbook.com/)
* [Github](https://github.com/tomwhite/hadoop-book/)
* [한빛](https://www.hanbit.co.kr/support/supplement_survey.html?pcode=B6473892834)

<hr>
<br>

## 하둡 기초 정보

#### 검색 엔진 개발의 한 부분으로 하둡이 개발되었으며, 빅데이터를 위한 범용 저장소 및 분석 플랫폼으로 인정을 받음

<br>

### 1. 하둡의 필요성
* 데이터의 증가량이 폭등하여 쌓여가는 현재의 디지털 세계 (2013년: 4.4ZB, 2020년: 44ZB) - 책이 2017년도에 작성됌
* 데이터 총량은 증가하는데, 데이터 읽기 속도는 1990년: 4.4MB, 2020년: 100MB 수준에 머뭄 + 쓰는 속도는 더 느림
  * 이를 해결하기 위해서, `병렬처리`가 필요
  * Hadoop의 `HDFS`과 `MapReduce`로 `병렬처리한 이후에 결합`을 하여 결과물을 만들어낸다

<br>

### 2. 하둡 생태계의 과거와 현재
* `MapReduce` :`일괄처리 시스템`이기에 전체 데이터에 대한 일괄 처리에 적합하다
  * 즉, 결과 값을 알기까지 시간이 걸리고, 사용자의 대기 시간이 긴 편
* 현재에는 일괄처리에 더불어서 `대화형 분석`을 포함하여 다양한 추가 기능들이 가능하게 에코시스템 내에서 다양한 SW들이 나타나고 있다
  * `대화형 SQL` : 매리듀스 대신 장기 실행 전용 데몬인 `임팔라 (Impala)`이나 컨테이너를 재사용하는 (`Tez 기반의 하이브`) 분산 쿼리 엔진을 사용하여, 빠른 응답 속도를 얻는다
  * `반복 처리`  : 머신러닝 관련 알고리즘은 반복 연산이 많은데, 그때 그때 다시 데이터를 디스크에서 읽어서 메모리에 적재하는 것이 아니라, `Spark`를 통해 `메모리에 임시로 작업 데이터셋을 보존`하여 바로 바로 사용하는 것이 효율적
  * `스트림 처리` : `Storm`, `Samza`, `Spark Streaming`과 같은 스트리밍 시스템은 실시간으로 실행되고 경계가 없는 스트림 데이터를 분산 계산하여 그 계산을 하둡 저장소나 외부 시스템에 보낼 수 있다
  * `검색` : `Solr` 검색 플랫폼을 통해 문서를 색인하여 HDFS에 저장하고, HDFS에 저장된 색인을 기반으로 검색 쿼리를 제공한다

<br>

### 3. MapReduce vs RDBMS

|               | 전통 RDBMS     | MapReduce         |
| ------------- | ------------- | ----------------- |
| 데이터 크기      | GB            | PB                 | 
| 접근 방식       | 대화형 및 일괄처리 | 일괄처리             | 
| 변경           | 여러 번 읽고 쓰기 | 한 번 읽고 여러 번 쓰기 |
| 트렌젝션        | ACID          | 없음                |
| 구조           | 쓰기 기준 스키마  | 읽기 기준 스키마       | 
| 무결성          | 높음           | 낮음                | 
| 확장성          | 비선형          | 선형               | 

<br>

### 4. MapReduce vs HPC(MPI) 
* High-performance Computing (HPC)과 그리드 컴퓨팅 커뮤니티는 Message Passing Interface (MPI)와 같은 API를 이용하여 대규모 데이터를 처리
  * HPC는 대체로 SAN으로 연결된 공유 파일시스템에 접근하는 클러스터 머신 여러 대에 작업을 분산 
* MapReduece는 가능하면 계산 노드에 데이터를 함께 배치하여 데이터 지역성 (Data Locality)을 활용하는 데이터 치리가 하둡의 핵심


<br>
<hr>
<br>
