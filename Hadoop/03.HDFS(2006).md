# HDFS (Hadoop Distributed File System, 2006)
> 분산 파일시스템 : 네트워크로 연결된 여러 머신의 스토리지를 관리하는 파일시스템
* 범용 하드웨어에서 구성된 클러스터에서 실행되고, 스트리밍 방식의 데이터 접근 방식으로 대용량의 데이터를 다룰 수 있게 설계된 파일시스템

<hr>
<br>

## 기본 개념
#### 결국은 HDFS은 File System이지만 Distributed되서 Parallel하게 데이터가 처리되는 FS


### [디스크]

* 구성 : Actuator, Spindle, Platter
  * Actuator : Arm, Head
  * Spindle : Motor
    * RPM : 분당 회전수로 기능 측정
  * Platter : Sector, Track, Cylinder
* Sector: 디스크의 최소 단위로 보통 512B 저장

<br>

### [파일시스템]
> 컴퓨터에서 파일이나 자료를 쉽게 발견 및 접근할 수 있도록 보관 또는 조직하는 체제
* 디스크의 최소 단위인 섹터는 크기가 보통 512B
  * 이에 따라, 만약 한 섹터 씩 읽고 크기가 큰 파일을 읽어야 한다면, 너무 많은 횟수로 읽어야 함
  * 이렇게 너무 작은 크기로 많이 읽는 비효율적인 부분을 해결하고자 파일시스템이 도입
* 파일시스템은 Cluster(Windows), Block(Unix) 단위를 논리적으로 생성하여, 다수의 섹터를 한 번 처리한다

<br>
<hr>
<br>

<div align="center">
 <img width="80%" src="https://user-images.githubusercontent.com/37537227/127886578-cf4138fe-0de4-4816-bafd-6b0f0b122ef6.png" />
</div>

<br>

## HDFS 구성
#### HDFS 클러스터는 Master-Worker 패턴으로 동작하는 두 종류의 노드인 `NameNode`(Master)와 `DataNode`(Worker)로 구성된다
#### DataNode들은 블록을 저장하고, 이에 대한 메타 정보를 NameNode가 관리하는 등 즉 NameNode가 네임스페이스를 관리한다

<br>

### [적합하지 않은 상황] 

* 빠른 데이터 응답시간
  * Hbase 필요

* 수 많은 작은 파일
  * 네임노드가 메타 정보를 메모리에서 관리하기 때문

* 다중 라이터와 파일의 임의 수정
  * 한 번 쓰거나 덧붙이는 것은 가능하나 임의 위치에 있는 내용을 수정하는 것은 허용하지 않는다

<br>

### [블록]

* 일반 디스크의 섹터 사이즈 : 0.512KB

* 기존 파일시스템의 블록 사이즈 : 0.512KB * {2, 4, 8}
  * 디스크에 쓰기를 할 때, 블록 크기만큼 점유

* HDFS의 Default 블록 사이즈 : `128MB`
  * 디스크에 쓰기를 할 때, 블록 크기보다 파일 사이즈가 작으면 파일 사이즈만큼만 점유 
  * 예) 파일 사이즈가 1MB면, 1MB만 디스크를 점유
  * 블록 크기가 결정되면, File은 `block-sized chunks`로 나뉘어져 저장

* 주요 개념
  * 현재 128MB가 최적의 크기로 알려져있지만, 너무 작으면 Name Node에게 부하가 발생하고, 너무 크면 병렬처리가 효과적으로 진행되기 어렵다는 개념
  * Replication Factor of Three : 모든 데이터에 대해서 3개의 사본을 각 Data Node가 가짐으로써 가용성을 증가시키지만, 그만큼 큰 디스크 공간을 차지한다는 개념  

<br>

### [Hadoop File Formats]

<div align="center">
 <img width="50%" src="https://user-images.githubusercontent.com/37537227/142764292-c5c4c027-dd33-4eaf-9a43-ae7b82cb21ce.png">
</div>

<br>

* 행 기반 : select update query on a single record, access an entire record
  * Sequence File : key-value format for MapReduce stored in a binary format
  * Avro : schema stored in a jason format

* 열 기반 : access only specific columns of an entire record
  * Parquet : stored in a binary format
  * ORC : best for hive

* .txt, .xml, .csv, .json 파일은 데이터 처리에 적합하지 않은 File Format
  * DataFrame 및 RDD로 변환해서 사용하는 이유

<br>

### [환경설정]
* 독립 (로컬) 모드 : 데몬이 실행되지 않고, 모든 것이 단독 JVM 내에서 실행
* 의사분산 모드 : 모든 하둡 데몬을 로컬 머신에서 실행
* 완전분산 모드 : 하둡 데몬을 여러 대의 머신으로 구성된 클러스터에서 실행

<br>

<div align="center">

| 구성요소 | 속성  | 독립  | 의사분산  | 완전분산  |
|----------|---|---|---|---|
| 공통      | FS.defaultFS  | file:///  | hdfs://localhost/  | hdfs://namenode/  |
| HDFS     | dfs.replication | N/A  | 1  | 3(기본)   |
| 맵리듀스   | mapreduce.framework.name  | local(기본)  | yarn  | yarn  |
| YARN     | yarn.resourcemanager.hostname  |  N/A  | localhost  | resourcemanager  |
|          | yarn.resourcemanager.aux-services  | N/A   | mapreduce_shuffle  | mapreduce_shuffle  |

</div> 
 
<br>
<hr>
<br>

## HDFS 명령어
#### 사용자 / 운영자 / 디버그 명령어로 구성 ([wikidocs 관련 글](https://wikidocs.net/26496))
#### Local에서 HDFS로 Load해서 사용하는 형식

<br>

### [hadoop | hdfs 명령어 가능]
```bash
hdfs dfs -ls / # File System 디렉토리 확인
hdfs fsck / -files -blocks # File System 디렉토리 상태 확인
hdfs dfs -put LogData/* /user/impala/LogData # local file을 HDFS로 로드
hdfs dfs -get [소스 경로] [로컬 경로]
hdfs dfs -rm <경로 혹은 파일명>

```
* `dfs` : 파일 시스템 쉘 명령어
* `fsck` : 파일 시스템 상태 체크
* hdfs 기본 디렉토리는 home 디렉토리로 `/user/<본인 이름>`이다

<br>
<hr>
<br>

## WebHDFS REST API
#### curl로 파일 CRUD 가능

<br>

### [Terminal]
```bash
curl -s http://$(hostname -f):5007/webhdfs/v1/user/hadoop/?op=LISTSTATUS
```
