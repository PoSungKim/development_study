# YARN (2012)
> 하둡 자원관리 시스템
* 수 백개 혹은 수 천개의 노드들로 구성되어 있는 하둡 클러스터에서 Job들을 어떻게 배치시킬지 그리고 배치되는 노드에 대한 자원 할당을 어떻게 분배할지 등을 관리해준다 
* [hadoop.apache.org](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html)

<hr>
<br>

## YARN 구성
#### The fundamental idea of YARN is to split up the functionalities of resource management and job scheduling/monitoring into separate daemons.
#### The idea is to have a global ResourceManager (RM) and per-application ApplicationMaster (AM). 
#### An application is either a single job or a DAG (Directed Acyclic Graph) of jobs.

<br>

<div align="center">
  <img width="60%" src="https://user-images.githubusercontent.com/37537227/146876206-1ca4b328-5845-4236-a240-480893f62267.png">
</div>

<br>

### [Client]
* Job Submission을 보내는 서버

<br>

### [Resource Manager - data-computation framework]
* `Global`
* Ultimate Authority
* Scheduler (allocating resources to the various running applications in the form of Containers, CapacityScheduler&FairScheduler)와 ApplicationsManager (accepting job-submissions, negotiating the first container for executing the application specific ApplicationMaster)로 구성

<br>

### [Node Manager - data-computation framework]
* `Per-machine` Framework Agent
* Containers 관리 및 리소스 모니터링 (cpu, memory, disk, network) 결과를 Resource Manager에게 공유

<br>

### [Applicaton Master]
* `Per-application`, `application specific`
* Resource Manager와 negotiate하고 Node Manager와 협업하여 Task 수행 및 모니터링을 직접 수행하는 라이브러리

<br>

### [Container]
* 할당 받는 Resource (memory, cpu, disk, network etc.)

<br>

### [Spark 작업 죽이기]

```bash
yarn application -list y
yarn logs -applicationId[] -log_files[] 
yarn application -kill AppID
```
* 

<br>
<hr>
<br>

## 전체 그림 예시
#### 

<br>

<div align="center">
  <img width="80%" alt="스크린샷 2021-12-21 오후 2 28 18" src="https://user-images.githubusercontent.com/37537227/146876302-5fb4c8bd-c2bf-4b61-9c75-3674ef6bd334.png">
</div>

<br>

### [Web UI]
* ResourceManager 웹 UI
* HistoryServer 웹 UI


