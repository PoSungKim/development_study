# MapReduce(2006)
> 데이터 처리르 위한 프로그래밍 모델
* 하둡은 다양한 언어로 작성된 Map Reduce Program을 구동시킬 수 있으며, 병행성을 고려하여 설계되었기 때문에 누구나 대용량 데이터셋 기반 대규모 데이터 분석 가능

<hr>
<br>

## 예제를 통한, MapReduce Programming Model 보기

#### 기상 데이터셋 (로그 데이터 ==> semi-structured, record-oriented 하기에 MapReduce 기반 데이터 분석에 적합)

<br>

### 데이터 포맷
* National Climatic Data Center (NCDC) 자료
* 한 행이 하나의 레코드
* 기상관측소별로 측정된 정보는 gzip으로 압축되어 연도별 디렉토리에 위치

<br>

### 유닉스 도구로 데이터 분석하기
* `awk` 명령어를 통한 분석이 가능하지만, `너무 오래`걸린다

<br>

### 하둡으로 데이터 분석하기
* 병렬처리를 하면 더욱 더 빠르게 분석 가능
* MapReduce = Map + Reduce
  * `Job` : 작업의 기본 단위
  * `Map` : Raw Data를 입력으로 받아서 필요 부분의 Data를 출력
  * `Reduce` : 필요 부분의 Data를 입력으로 받아서 최종 목표 계산 값을 출력
    * 각 단계의 `입력`과 `출력` 값은 `(키, 값)`의 쌍을 가진다   

<br>

### [Java Mapper 예제]
> org.apache.hadoop.mapreduce.Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT>
```java
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class MaxTemperatureMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    ...
}
```
* Mapper는 클라스

<br>

### [Java Reducer 예제]
> org.apache.hadoop.mapreduce.Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT>
```java
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class MaxTemperatureReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    ... 
}
```
* Reducer도 클라스

<br>

### [Java Job 예제]
```java
import org.apache.hadoop.mapreduce.Job;

public class MaxTemperature {
    public static void main(String[] args) throws Exception {
        Job job = new Job();
        job.setJarByClass(MaxTemperature.class);
        job.setJobName("Max temperature");
        ...
    }
}
```
* 하둡 클러스터에서 잡을 실행할 때는 JAR 파일로 먼저 묶어서 JVM에서 실행시킨다

<br>
<hr>
<br>

## 설치 및 환경 설정

#### 설치 및 환경 설정에 부담을 느낀다면, `Cloudera QuickStart VM`을 설치해서 진행하는 것도 한 방법

<br>

### [하둡 설치]
```bash
java -version

tar xzf hadoop-x.y.z.tar.gz

hadoop -verison

hdfs
```

<br>
<hr>
<br>

## 분산형으로 확장하기

#### 로컬 파일시스템 >> HDFS 분산 파일시스템으로 확장

<br>

### [데이터 흐름]
> MapReduce Job : 클라이언트가 수행하는 작업의 기본 단위 
* Job = Map Task + Reduce Task
  * 각 Task는 YARN을 이용하여 스케줄링되고 클러스터의 여러 노드에서 실행된다
* 하둡 맵리듀스 잡의 입력 = Input Split
  * 각 Split마다 맵 태스크를 생성하고 스필릿의 각 레코드를 사용자 정의 맵 함수로 처리
* 전체 입력을 다수의 스플릿으로 나누고, 각 스플릿의 크기는 HDFS 블록의 크기와 같게 하면 효과적 (보통, 128MB이지만, 개별 설정 가능)
  * 이는 Data Locality Optimization을 위한 설정으로, HDFS 블록 크기가 단일 노드에 저장된다고 확신할 수 있는 가장 큰 입력 크기이기 때문
    * Map Task를 위해 필요한 데이터가 로컬에 다 있어야 제일 효과적이라는 의미
  * `클러스터의 중요한 공유 자원인 네트워크 대역폭을 사용하지 않는 방법`이 매우 중요!
* Map Task의 결과는 HDFS가 로컬이 아닌 로컬 디스크에 저장된다
