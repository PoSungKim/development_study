# Impala와 Spark의 Hive의 Metastore 연동
> 기본적으로 HDFS은 분산 파일시스템이기 때문에 RDBMS의 테이블 형식의 파일 포맷을 알지 못한다
* 이에 따라, HDFS 기반의 데이터이라도, RDBMS처럼 사용할 수 있도록 Meta 정보를 만들어서 활용한다 
* Hive는 이러한 메타 정보를 따로 RDBMS에 저장한다 >> 이 RDBMS가 metastore가 된다
<br>

## Impala 
> invalidate metadata    // 메타 정보 업데이트 (변경 사항에 대해서 바로 바로 수행 필요)

> compute stats [테이블명] // 통계 자료 업데이트

#### Hive의 Metastore를 가져와서 내부 Impala 캐시에 저장해서 사용하기 때문에, Impala에서 처리한 연산에 대한 통계 및 메타 정보를 내부 캐시와 Metastore에 지속적으로 업데이트해줘야 한다


<br>

<div div ="80%" align="center">
  <img src="https://user-images.githubusercontent.com/37537227/128119663-5be63a7d-22d1-450d-b381-9a948e5cf2f2.png" />
</div>

<br>


### [데이터 포맷과 경로를 결정하기 위해 Metastore]
```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
  (col_name data_type
    [COMMENT 'col_comment']
    [, ...]
  )
  [PARTITIONED BY (col_name data_type [COMMENT 'col_comment'], ...)]
  [SORT BY ([column [, column ...]])]
  [COMMENT 'table_comment']
  [ROW FORMAT row_format]
  [WITH SERDEPROPERTIES ('key1'='value1', 'key2'='value2', ...)]
  [STORED AS file_format]
  [LOCATION 'hdfs_path']
  [CACHED IN 'pool_name' [WITH REPLICATION = integer] | UNCACHED]
  [TBLPROPERTIES ('key1'='value1', 'key2'='value2', ...)]
```

<br>

### [예시] 

``` sql
CREATE TABLE jobs (
 id INT,
 title STRING,
 salary INT,
 posted TIMESTAMP
 )        # 데이터 타입 명시
 ROW FORMAT DELEMITED                          # 테이블 구분 지정.
 FIELDS TERMINATED BY ‘ , ’                    # ‘, ’ 로 데이터 구분
 STORED AS {TEXTFILE|SEQUENCEFILE|...}         # STORED AS TEXTFILE이 디폴트
 LOCATION ‘/loudacre/jobs’ ;                   # hdfs 파일 경로까지 지정 
```

* RDBMS에서 데이터의 테이블 구조와 경로를 얻고 쿼리를 통해 데이터를 HDFS로 옮겨줍니다.

<br>

### [예시]

``` sql
SHOW TABLES;
DESCRIBE jobs;
DESCRIBE FORMATTED jobs;
SHOW CREATE TABLE jobs;
```
* Create Table 시, 현재 세팅에서는 `Stored As Textfile`와 `LOCATION`이 자동으로 설정되었다
  * Metastore와 File Data를 분리해서 봐야한다 

<br>

### []
* dd


## 중요한 점은 Drop Table을 하더라도 HDFS Location에 있는 파일도 자동으로 삭제되지는 않는다는 것이다
## 이에 따라, drop table [tablename] PURGE 명령어를 통해 Location에 위치한 파일도 같이 삭제 가능하다

