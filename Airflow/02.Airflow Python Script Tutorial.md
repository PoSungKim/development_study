# Airflow Python Script Tutorial
> Airflow DAG 객체를 생성하기 위해 DAG의 구조를 표현한 Configuration File이라는 점을 숙지해야 한다고 한다. 
* 실제로 데이터가 처리되지 않는다. Oozie의 worflow.xml 역할로 보임.

<hr>
<br>

## Tutorial
#### ~/airflow/dags/*.py 형태로 Script 작성

<br>

### [Importing Modules]
```python
from datetime import datetime, timedelta
from textwrap import dedent

# The DAG object; we'll need this to instantiate a DAG
from airflow import DAG

# Operators; we need this to operate!
from airflow.operators.bash import BashOperator
```

<br>

### [Default Arguments]
```python
# These args will get passed on to each operator
# You can override them on a per-task basis during operator initialization
default_args={
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    # 'queue': 'bash_queue',
    # 'pool': 'backfill',
    # 'priority_weight': 10,
    # 'end_date': datetime(2016, 1, 1),
    # 'wait_for_downstream': False,
    # 'sla': timedelta(hours=2),
    # 'execution_timeout': timedelta(seconds=300),
    # 'on_failure_callback': some_function,
    # 'on_success_callback': some_other_function,
    # 'on_retry_callback': another_function,
    # 'sla_miss_callback': yet_another_function,
    # 'trigger_rule': 'all_success'
},
```
* DAG 생성시, 각 Operator에게 전달할 공통 Parameter

<br>

### [Instantiate a DAG]
```python
with DAG(
    'tutorial',
    # These args will get passed on to each operator
    # You can override them on a per-task basis during operator initialization
    default_args={
        'depends_on_past': False,
        'email': ['airflow@example.com'],
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
        # 'queue': 'bash_queue',
        # 'pool': 'backfill',
        # 'priority_weight': 10,
        # 'end_date': datetime(2016, 1, 1),
        # 'wait_for_downstream': False,
        # 'sla': timedelta(hours=2),
        # 'execution_timeout': timedelta(seconds=300),
        # 'on_failure_callback': some_function,
        # 'on_success_callback': some_other_function,
        # 'on_retry_callback': another_function,
        # 'sla_miss_callback': yet_another_function,
        # 'trigger_rule': 'all_success'
    },
    description='A simple tutorial DAG',
    schedule_interval=timedelta(days=1),
    start_date=datetime(2021, 1, 1),
    catchup=False,
    tags=['example'],
) as dag:
```

<br>

### [Tasks]
```python
t1 = BashOperator(
    task_id='print_date',
    bash_command='date',
)

t2 = BashOperator(
    task_id='sleep',
    depends_on_past=False,
    bash_command='sleep 5',
    retries=3,
)
```
* 사전에 Default Argument로 정의한 설정들이 BashOperator가 기억을 하고 있어서 Task를 Instantiate할 때 주입해준다
  * BashOperator()에 다시 정의하면 다시 정의된 설정으로 override해서 적용된다
* Parameter 정의 Rule
  * Explicitly passed arguments
  * Values that exist in the default_args dictionary
  * The operator’s default value, if one exists

<br>

### [Templating with Jinja]
* 사용 가능하다고 한다

<br>

### [Adding DAG and Tasks documentation]
* javadocs 같이 documentation 가능

<br>

### [Setting up Dependencies bw/ Tasks]
```python
t1.set_downstream(t2)

# This means that t2 will depend on t1
# running successfully to run.
# It is equivalent to:
t2.set_upstream(t1)

# The bit shift operator can also be
# used to chain operations:
t1 >> t2

# And the upstream dependency with the
# bit shift operator:
t2 << t1

# Chaining multiple dependencies becomes
# concise with the bit shift operator:
t1 >> t2 >> t3

# A list of tasks can also be set as
# dependencies. These operations
# all have the same effect:
t1.set_downstream([t2, t3])
t1 >> [t2, t3]
[t2, t3] << t1
```

<br>

### [Time Zone 세팅은 pendulum을 통해서 설정]

<br>
<hr>
<br>
