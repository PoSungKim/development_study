# 주요 개념(2014)
> Platform to programmatically author, schedule and monitor workflows.
* `Oozie`, `Azkaban` 등과 거론되며 Workflows를 `DAGs of Tasks`로 표현하며 처리한다.
* [Apache Airflow Official Website](https://airflow.apache.org/docs/apache-airflow/stable/index.html)

<hr>
<br>

## 기본 특징
#### AirBnb에서 시작된 프로젝트로 오픈소스화된 이후에 Apache 재단에서 `Top-Level Project`로 선정되었다

<br>

### [History]
* 2014 : Airflow was started in October 2014 by Maxime Beauchemin at Airbnb. 
* 2015 : It was open source from the very first commit and officially brought under the Airbnb GitHub and announced in June 2015.
* 2016 : The project joined the Apache Software Foundation’s Incubator program in March 2016
* 2019 : The Foundation announced Apache Airflow as a Top-Level Project in January 2019.

<br>

### [Principles]
* Dynamic:
  * Airflow pipelines are configuration as code (Python), allowing for dynamic pipeline generation. This allows for writing code that instantiates pipelines dynamically.
* Extensible: 
  * Easily define your own operators, executors and extend the library so that it fits the level of abstraction that suits your environment.
* Elegant: 
  * Airflow pipelines are lean and explicit. Parameterizing your scripts is built into the core of Airflow using the powerful `Jinja templating engine`.
* Scalable: 
  * Airflow has a modular architecture and uses a message queue to orchestrate an arbitrary number of workers. Airflow is ready to scale to infinity.

<br>
<hr>
<br>

## 기본 세팅
#### 2022-03-27 날짜, Airflow 2.2.4 버전, Python 3.6 기준으로 세팅

<br>

### [Prerequisites]
* Python: 3.6, 3.7, 3.8

* Databases:
  * PostgreSQL: 9.6, 10, 11, 12, 13
  * MySQL: 5.7, 8
  * SQLite: 3.15.0+

* Kubernetes: 1.16.9, 1.17.5, 1.18.6

<br>

### [Installation && Standalone Run]
```bash
# Airflow needs a home. `~/airflow` is the default, but you can put it
# somewhere else if you prefer (optional)
export AIRFLOW_HOME=~/airflow

# Install Airflow using the constraints file
AIRFLOW_VERSION=2.2.4
PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
# For example: 3.6
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
# For example: https://raw.githubusercontent.com/apache/airflow/constraints-2.2.4/constraints-3.6.txt
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"

# The Standalone command will initialise the database, make a user,
# and start all components for you.
airflow standalone

# Visit localhost:8080 in the browser and use the admin account details
# shown on the terminal to login.
# Enable the example_bash_operator dag in the home page
```
* Poetry or pip-tools은 권장하지 않고 pip으로 설치하는 것을 권장

<br>

```bash
Installing collected packages: ...flask-wtf, Flask-SQLAlchemy, flask-session, Flask-OpenID, flask-login, Flask-JWT-Extended, flask-caching, Flask-Babel, connexion, flask-appbuilder, apache-airflow
```
* airflow 내부는 Flask로 구성되어 있음을 파악 가능

<br>

### [Standalone 모드 - 컴포넌트 별로 실행]

```bash
# Airflow Directory
cd $HOME/airflow

# Check Configuration 
airflow config list

# Metastore (SQLite Database)
airflow db init   

# Scheduler
airflow scheduler

# Web UI
airflow webserver -p 8080
```
<div align="center">
    <img width="80%" src="https://user-images.githubusercontent.com/37537227/160281027-d86ea6fa-fa0c-41fe-a0a1-312007dd2d7d.png">
</div>

<br>

### [로그인]

```bash
# Login Info
airflow users create \
          -u admin \
          -f FIRST_NAME \
          -l LAST_NAME \
          -r Admin \
          -e admin@example.org
          
[2022-03-17 00:07:52,252] {manager.py:214} INFO - Added user admin
User "admin" created with role "Admin"
```

<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158622781-86037284-df24-45af-9928-c3e0aa56ea9d.png">
</div>

<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158622595-53ebba50-0a5b-4b7d-a187-80f0d157bf6f.png">
</div>

<br>

### [Other CLI Commands]
```bash
airflow -h
```

```bash
positional arguments:
  GROUP_OR_COMMAND

    Groups:
      celery         Celery components
      config         View configuration
      connections    Manage connections
      dags           Manage DAGs
      db             Database operations
      jobs           Manage jobs
      kubernetes     Tools to help run the KubernetesExecutor
      pools          Manage pools
      providers      Display providers
      roles          Manage roles
      tasks          Manage tasks
      users          Manage users
      variables      Manage variables

    Commands:
      cheat-sheet    Display cheat sheet
      info           Show information about current Airflow and environment
      kerberos       Start a kerberos ticket renewer
      plugins        Dump information about loaded plugins
      rotate-fernet-key
                     Rotate encrypted connection credentials and variables
      scheduler      Start a scheduler instance
      standalone     Run an all-in-one copy of Airflow
      sync-perm      Update permissions for existing roles and optionally DAGs
      triggerer      Start a triggerer instance
      version        Show the version
      webserver      Start a Airflow webserver instance

```

<br>

### [Run Dags]
```bash
airflow dags list
```

```bash
dag_id                                  | filepath                                                                                                  | owner   | paused
========================================+===========================================================================================================+=========+=======
example_bash_operator                   | /opt/homebrew/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py                   | airflow | True
example_branch_datetime_operator_2      | /opt/homebrew/lib/python3.9/site-packages/airflow/example_dags/example_branch_datetime_operator.py        | airflow | True
```

```bash
airflow tasks list example_bash_operator
```

```bash
lso_run_this
run_after_loop
run_this_last
runme_0
runme_1
runme_2
this_will_skip
```

```bash
airflow dags trigger -e 2022-03-15 example_bash_operator
```

<br>
<hr>
<br>

## Web UI
#### 

<br>

### [HomePage - Dags]
<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158630352-c184d3a4-1ad0-4358-a520-bf9153f58fc7.png">
</div>

* Recent Tasks
  * none
  * removed
  * scheduled
  * queued
  * running
  * success
  * shutdown
  * restarting
  * failed
  * up_for_retry
  * up_for_reschedule
  * upstreamed_failed
  * skipped
  * sensing
  * deferred


<br>

### [Schedule]
<div align="center">
  <img width="70" src="https://user-images.githubusercontent.com/37537227/158633395-a5b8b4b8-79c4-4604-8b36-8fbc8be0fb62.png">
  <img width="60%" src="https://user-images.githubusercontent.com/37537227/158633146-7c15b42a-50d5-419f-8fce-fc806a767d30.png">
</div>

<br>

### [Links]
<div align="center">
    <img width="80%" src="https://user-images.githubusercontent.com/37537227/158634575-36216b85-1401-4869-98cf-faa7ef687c45.png">
</div>

<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158636806-2aa0c291-45fc-49d8-ac25-17adeba1ea1a.png">
</div>
  
<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158636654-c64fe88a-b562-43f5-8255-594c525483d3.png">
</div>

<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158638944-6cd1a619-73a0-4f57-aa08-b831046de460.png">
</div>

<div align="center">
  <img width="80%" src="https://user-images.githubusercontent.com/37537227/158639714-035c215b-f8df-44e3-9fc9-85d3070718ab.png">
</div>

* Code : Dag 파일 바로 확인 가능

<br>
<hr>
<br>
